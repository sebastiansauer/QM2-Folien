---
title: "QM2-Thema5-Fallstudie1: Filmbewertungen"
author: "ses"
date: "`r Sys.time()`"
output: 
  html_document:
    toc: TRUE
    number_sections: TRUE
editor_options: 
  chunk_output_type: console
---

# Vorbereitung

```{r global-knitr-options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H',
  fig.asp = 0.618,
  fig.width = 5,
  fig.cap = "", 
  out.width = "50%",
  fig.path = "",
  fig.align = "center",
  fig.show = "hold",
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = FALSE)
```


## R-Pakete 

```{r message=FALSE}
library(rstanarm)  # Bayes-Modelle
library(tidyverse)  # Datenjudo
library(bayesplot)  # Plotting
library(gt)  # Tabellen
library(parallel)  # Turbo
library(rstatix)  # Deskriptive Statistiken
library(bayestestR)  # Vernachl√§ssigbare Unterschiede/Zusammenh√§nge
#library(see)  # Visualisierung
library(tictoc)  # Zeit messen, wie lange das Modell rechnet
```



Turbo einschalten:

```{r}
options(mc.cores = parallel::detectCores())
```



## Daten: Filmbeurteilung


```{r}
library(ggplot2movies)
data(movies)
```

Hilfe zu den Daten gibt es hier:

```{r eval = FALSE}
help(movies)
```



# Hingergrund


## Bezug zum Studiengang AWM

Nach dem Studium haben Sie bei einem Online-H√§ndler angeheuert und zwar in der Medien-Abteilung. Der Hinweis, dass Sie etwas mit Medien studiert haben gen√ºgte. Vielleicht war auch die Behauptung, dass Sie der absolute R-Checker seien n√ºtzlich, um den Job zu bekommen ... Jedenfalls m√ºssen Sie den Behauptungen Taten folgen lassen, Schluck!



## Forschungsfrage

*Wie (stark) ist der Zusammenhang von logarithmierten Budget und Bewertung eines Films?*

Unser Kunde -- ein reicher M√§zen mit extrentischem Lebenswandel, der gerne ein paar Millionen invetieren m√∂chte -- geht von einem positivem Zusammenhang, $\beta$ aus. Entsprechend sei unsere Hypothese $H_1: \beta > 0$.


# Explorative Analyse


## Datensatz vorverarbeiten 

Es macht f√ºr Analysen, die in Stan laufen immer Sinn

- nur die relevanten Variablen in die Analyse aufzunehmen
- fehlende Werte zu entfernen
- vorab (vor dem Modellieren) etwaige Transformationen (wie Quadrieren, logarithmieren) vorzunehmen 

```{r}
movies <-
  movies %>% 
  mutate(budget_log10 = log10(budget))

movies2 <-
  movies %>% 
  select(budget_log10, rating) %>% 
  drop_na() %>% 
  filter(budget_log10 != -Inf)
```


Einige Filme haben ein Budget von 0. Das Logarithmus von 0 ist aber minus Unendlich. Mit dieser "Zahl" kann man nicht rechnen. Daher filtern wir alle Zeilen mit `-Inf` heraus.


## Logarithmus

`budget_log10` fasst die Gr√∂√üenordnung des Budgets:

- 1000: 10^3 -> log10(10^3) = 3
- 10000: 10^4 -> log10(10^4) = 4
- 100000: 10^5 -> log10(10^5) = 5

Wir nehmen also die Gr√∂√üenordnung heran, nicht den Betrag selber.

Das gef√§llt unserem Auftraggeber erstmal nicht.

Aber, sagt er, und das zu Recht, entscheidend ist ja nicht die Stichprobe, sondern die Population. Weswegen wir uns bitte sch√∂n sofort an die Inferenzstatistik bewegen sollten.

Aha, unser M√§zen kennt sich also sogar mit Statistik aus.


## Deskriptive Statistiken


```{r}
movies2 %>% 
  get_summary_stats() %>% 
  gt()
```



## Zusammenhang im Datensatz visualisieren

```{r}
plot0 <- movies %>% 
  ggplot(aes(x = budget_log10, y = rating)) +
  geom_point(alpha = .2)

plot0 +
  geom_smooth(method = "lm")
```
Es scheint  einen sehr schwachen, negativen Zusammenhang zu geben.



# Modellefinition




## Priors

Wir gehen von folgenden Priori-Werten aus:

- $\alpha \sim N(7,1)$: Rating-Mittelwert
- $\beta \sim N(0,1)$: Zusammenhang log10-Budget und Rating `b=1` hie√üe: √§ndert sich das Log10-Budget um 1 Einheit (d.h eine Gr√∂√üenordnung, also Faktor 10), so √§ndert sich das Rating um 1 Einheit
- $\sigma \sim Exp(1)$: Streuung um $\mu_i$


Das sind keineswegs besonders schlaue Prioris. K√∂nnten wir unseren M√§zen befragen, er scheint ja Experte zu sein, k√§men wir vielleicht zu kl√ºgeren Prioris (allerdings ist der M√§zen gerade auf einer "Musen-Reise" und nicht zu sprechen).


## Likelihood

- $r_i \sim N(\mu_i, \sigma)$

mit $r_i$: Rating f√ºr Film $i$

## Lineares Modell


- $\mu_i = \alpha + \beta_1 b$



# Modell in R

## Modell 1: Standard-Priors (`post1`)

### Modellefinition in R (rstanarm)

```{r}
post1 <- stan_glm(rating ~ budget_log10,
               data = movies2
               #, refresh = 0
               )  # Mit `refresh = 0` bekommt man nicht so viel Ausgabe
```


Einige Infos zu den Priori-Werten bei `stan_glm()` findet sich [hier](https://cran.r-project.org/web/packages/rstanarm/vignettes/priors.html).


### Priors

Welche Priori-Werte wurden (per Standard) gew√§hlt?

```{r}
prior_summary(post1)
```


Mit `coefficients` ist das Regressionsgewicht $\beta$ gemeint.


### Posteriori-Verteilung

√úberblick √ºber die Parameter:

```{r}
print(post1)
```


Langfassung:

```{r}
summary(post1)
```


Nur die mittleren Sch√§tzwerte f√ºr die Regression:

```{r}
coef(post1)
```


Man kann sich die Posteriori-Intervalle so ausgeben lassen:

```{r}
posterior_interval(post1) %>% 
  round(2)
```

Wir wissen jetzt also schon das Wesentliche: Mit einer Wahrscheinlichkeit von 90% liegt der Zusammenhang (das Beta-Gewicht) f√ºr Log-Budget zwischen -0.13 und -0.07. Es gibt also einen gewissen, negativen Zusammenhang zwischen Budget und Bewertung eines Films, laut unserem Golem zumindest.


### Visualisieren


#### Priori-Verteilung



```{r echo = TRUE, eval = TRUE}
post1_prior_pred <- stan_glm(rating ~ budget_log10,
               data = movies2,
               prior_PD = TRUE  # DIESER Schalter gibt uns die Prior-Pr√§diktiv-Verteilung
               #, refresh = 0
               )  # Mit `refresh = 0` bekommt man nicht so viel Ausgabe
```



Aus der [Hilfeseite](https://www.rdocumentation.org/packages/rstanarm/versions/2.21.1/topics/stan_glm):

`prior_PD    A logical scalar (defaulting to FALSE) indicating whether to draw from the prior predictive distribution instead of conditioning on the outcome.`

```{r}
post1_prior_pred
```


Die Koeffizienten aus `post1_prior_pred` sind also *rein* durch die Priori-Werte definiert; die Daten sind nicht eingeflossen.


Wenn wir das Objekt mit `as_tibble()` in eine Tabelle umwandeln, bekommen wir eine Tabelle mit den Stichproben:

```{r}
post1_prior_pred_draws <- 
  post1_prior_pred %>% 
  as_tibble() %>% 
  rename(a = `(Intercept)`,  # sch√∂nere, einfachere Namen
         b = budget_log10) %>% 
  slice_sample(n = 100)
```



```{r prior-post1-plot, echo = TRUE, eval = FALSE}
movies2 %>% 
  ggplot() +
  geom_point(aes(x = budget_log10, y = rating)) + 
  geom_abline(data = post1_prior_pred_draws,
aes(intercept = a, slope = b), color = "skyblue", size = 0.2)

```


Puh, die Priori-Werte sind ... vogelwildüê¶ .




#### Posteriori-Verteilung: Regressionsgerade 

```{r}
plot1 <- plot0 +
  geom_abline(intercept = coef(post1)[1],
              slope = coef(post1)[2],
              color = "blue")
plot1
```


```{r}
col_names <- c("a", "b", "sigma")
draws_m1 <-
  post1 %>% 
  as_tibble() 

names(draws_m1) <- col_names
```

Ein Blick in die ersten paar Zeilen der Post-Stichproben:

```{r}
draws_m1 %>% 
  slice_head(n=10) %>% 
  gt() %>% 
  fmt_number(everything(), decimals = 1)
```


Und hier die Posteriori-Verteilung f√ºr $\alpha$ und $\beta$ visualisiert:

```{r}
plot0 +
  geom_abline(data = draws_m1,
              aes(intercept = a,
                  slope = b),
              color = "skyblue1",
              alpha = .1) +
  geom_abline(intercept = coef(post1)[1],
              slope = coef(post1)[2],
              color = "blue")
```





#### Verteilung von $\beta$


Hier die Verteilung f√ºr die Steigung (Regressionsgewicht $\beta$):

```{r}
draws_m1 %>% 
  ggplot(aes(x = b)) +
  geom_density()
```


#### Posterior-Intervalle



Die Posteriori-Intervalle kann man sich schn√∂de mit `plot()` ausgeben lassen, wobei man als Parameter den Namen des Modells √ºbergibt.

```{r}
plot(post1)
```


Es gibt aber auch andere Darstellungsarten, z.B. als Dichtediagramme:


```{r}
mcmc_areas(post1) +
  labs(title = "Posteriori-Verteilung",
       caption = "Gezeigt werden Median und 50% bzw. 90% Perzentil-Intervalle")
```

S. [Hilfe hier](https://mc-stan.org/bayesplot/reference/MCMC-intervals.html)


Man kann sich auch angeben, welchen Parameter man visualisieren m√∂chte, und zwar mit dem Argument `pars` (wie *paramters*).


Oder nur das Posteriori-Interval f√ºr den Regressionskoeffizienten:

```{r}
mcmc_areas(post1,
           pars = "budget_log10")
```


### Fazit


Die Wahrscheinlichkeit, dass der Zusammenhang in Wirklichkeit zwischen -0.15 und -0.05 ist, ist sehr hoch.

Aber was bedeutet das, wie interpretiert man den Befund?

Rufen wir uns dazu ins Ged√§chtnis, was log10 bedeutet: Es bedeutet, dass man das Budget mit 10 multipliziert, also verzehnfacht, sozusagen eine Null hintendran schreibt.

Also: *Verzehnfacht man das Budget, so verringert sich mittlere Bewertung um etwa 0.15 bis 0.05 Punkte.*

Ob das viel ist, muss ein Medienexperte beantworten. Vielleicht sind Sie ja einer!


## Modell 2: Informierte (?) Priors

Kramen wir all unser Wissen √ºber Filme und die Filmindustrie zusammen! Wie wichtig sind die Kohlen f√ºr die G√ºte eines Films? Haben die einen gro√üen Einfluss? 

(Wenn wir von "Einfluss" sprechen, denken wir sicher automatisch an *kausalen* Einfluss. Jedenfalls geht es mir so und ich glaube, es ist schwierig, nicht an kausalen Einfluss, sondern nur an blanke Assoization, zu denken).


### Modellefinition in R (rstanarm)


Nach langem Beratschschlagen mit Film-Experten gehen wir davon aus, dass es im Prinzip - "normalerweise" keinen Zusammenhang gibt. Allerdings hat man in Filmen schon Pferde kotzen gesehen, deswegen wollen wir unseren Golem zu verstehen geben, dass er sich auch auf √úberraschungen einstellen soll ...

Kurz gesagt, auf Golem-Sprech:

$$\beta = \mathcal{N}(0,0.2)$$

Mit anderen Worten, verzehnfacht man das Budget, erwarten wir eine Ver√§nderung von (in 95% der F√§lle) nicht mehr als ¬±0.4 Rating-Punkte.

F√ºr die √ºbrigen Priorwerte greifen wir auf wenig ambitionierte Standardwerte zur√ºck.

```{r}
post2 <- stan_glm(rating ~ budget_log10,
               data = movies2,
               prior_intercept = normal(6, 1),  # alpha
               prior_aux = exponential(1),  # sigma
               prior = normal(0, .2),  # beta
               refresh = 0)  # Nicht so viel Ausgabe
```


Um Rechenzeit zu sparen, kann man das Modell auch speichern:

```{r eval = FALSE}
save(post1, file = "post2.rda")
load(file = "post2.rda")
```


### Priors

```{r}
prior_summary(post2)
```



### Prior-Pr√§diktiv-Verteilung

#### Berechnen der Prior-Pr√§diktiv-Verteilung

```{r}
tic()
post2_prior_pred <- stan_glm(rating ~ budget_log10,
                             data = movies2,
                             prior_intercept = normal(6, 1),  # alpha
                             prior_aux = exponential(1),  # sigma
                             prior_PD = TRUE,  # Prior-Pr√§diktiv-Verteilung
                             prior = normal(0, .2),  # beta
                             refresh = 0)  # Nicht so viel Ausgabe
toc()
```



#### Visualisierung der Prior-Pr√§diktiv-Verteilung

Dazu gehen wir vor wie f√ºr Modell 1, `post1`. Zuerst wandeln wir das Objekt `post2` in eine Tabele mit den Stichproben aus der Post-Verteilung um:

```{r}
post2_prior_pred_draws <- 
  post2_prior_pred %>% 
  as_tibble() %>% 
  rename(a = `(Intercept)`,  # sch√∂nere, einfachere Namen
         b = budget_log10) %>% 
  slice_sample(n = 100)
```


Und dann visualsieren



```{r prior-post2-plot, echo = TRUE, eval = FALSE}
movies2 %>% 
  ggplot() +
  geom_point(aes(x = budget_log10, y = rating)) + 
  geom_abline(data = post2_prior_pred_draws,
aes(intercept = a, slope = b), color = "skyblue", size = 0.2)
```


Sieht doch schon viel besser aus. üèÜ


### Posteriori-Verteilung


#### Kurzfassung

√úberblick √ºber die Parameter:

```{r}
print(post2)
```


Nur die mittleren Sch√§tzwerte f√ºr die Regression:

```{r}
coef(post2)
```


#### Langfassung

Ausf√ºhrlicher:

```{r}
summary(post2)
```


### Visualisieren


#### Regressionsgerade 

```{r}
plot1_m2 <- plot0 +
  geom_abline(intercept = coef(post2)[1],
              slope = coef(post2)[2],
              color = "blue")
plot1_m2
```

Erstellen wir eine Tabelle nur mit den Post-Samples:

```{r}
col_names <- c("a", "b", "sigma")
draws_m2 <-
  post2 %>% 
  as_tibble() 

names(draws_m2) <- col_names
```

Die ersten paar Werte aus der Tabelle mit Post-Samples:

```{r echo = FALSE}
draws_m2 %>% 
  slice_head(n=10) %>% 
  gt() %>% 
  fmt_number(everything(), decimals = 1)
```

Und hier die Regressionsgerade mit dem "Unsicherheitsbereich" f√ºr die Regressionskoeffizienten.

```{r}
plot0 +
  geom_abline(data = draws_m2,
              aes(intercept = a,
                  slope = b),
              color = "skyblue1",
              alpha = .1) +
  geom_abline(intercept = coef(post2)[1],
              slope = coef(post2)[2],
              color = "blue")
```

#### Verteilung von $\beta$


```{r}
draws_m2 %>% 
  ggplot(aes(x = b)) +
  geom_density()
```


#### Posterior-Intervalle

S. [Hilfe hier](https://mc-stan.org/bayesplot/reference/MCMC-intervals.html)

```{r}
mcmc_areas(post2) +
  labs(title = "Posteriori-Verteilung",
       caption = "Gezeigt werden Median und 50% bzw. 90% Perzentil-Intervalle")
```


```{r}
mcmc_intervals(post2,
               pars = "budget_log10") 
```



```{r}
mcmc_areas(post2,
           pars = "budget_log10") +
  labs(title = "Posteriori-Verteilung",
       caption = "Gezeigt werden Median und 50% bzw. 90% Perzentil-Intervalle")
```

Das ist das Gleiche wie unser Dichte-Diagramme etwas weiter oben.

### Quantile

```{r}
summary(post2)
```

Laut dem Modell (`post2`) liegt der Regressionskoeffizient mit 90% Wahrscheinlichkeit eng um -0.1 herum.

Genauer gesagt: $90\%PI_b: (-0.13, -0.07)$:

```{r}
draws_m2 %>% 
  summarise(b_90pi = quantile(b, probs = c(0.05, .95)))
```

```{r}
posterior_interval(post2)
```


### Wahrscheinlichkeiten f√ºr Parameterwerte

#### Positiver Zusammenhang

$p(b > 0|D)$

mit "D", den Daten des Modells.

```{r}
draws_m2 %>% 
  count(b > 0)
```


Die Wahrscheinlichkeit ist praktisch Null, dass der Zusammenhang positiv ist.



### $R^2$


```{r}
tic()
post2_r2 <- 
  bayes_R2(post2) %>% 
  as_tibble()
toc()
```


```{r}
post2_r2 %>% 
  ggplot(aes(x=value)) +
  geom_density()
```


```{r}
post2_r2 %>% 
  summarise(r2_mean = mean(value),
            r2_median = median(value))
```
Der Anteil erkl√§rter Varianz ist praktisch Null.


Der Golem blickt es nicht! Das Modell ist schlecht. 




### PPV

#### PPV berechnen

Simulieren wir den Erfolg neuer Filme; dabei betrachten wir das Budget von $10^3$ bis $10^8$ (6 Werte). Wir ziehen pro Budgetwert 1000 Stichproben aus der PPV.

```{r}
neue_Filme <- tibble(
  budget_log10 = 3:8)
```


Warum `3` bis `8`? Das sind genau die Werte f√ºr `budget_log10`, die wir in daten Daten haben.

Wie viel delogarithmiertem, also "richtigem" Budget entspricht das?

```{r}
10^(3:8)
```

- $10^3 = 1,000$
- $10^4 = 10,000$
- ...
- $10^8 = 100,000,000$


```{r}
ppv_m2 <- 
  posterior_predict(post2, neue_Filme, draws = 1e3) %>% 
  as_tibble() 


dim(ppv_m2)  # Zeilen, Spalten
```


Leider werden unsere Eingabewerte (3 bis 8) zerhauen, stattdessen wird 1 bis 6 zur√ºckgegeben. K√ºmmern wir uns gleich darum.


Hier ein Blick in die Tabelle `ppv_m2`: 

```{r echo = FALSE}
ppv_m2 %>% 
  head() %>% 
  gt() 
```

√Ñndern wir die Spaltennamen von 1,2,...6, in 3,4,...,8 um.

Reine Zahlen werden als Spaltennamen nicht akzeptiert, deswegen wandeln wir nohc die Zahl `3` in den Text `"3"` um, mit `as.character()`: 

```{r}
names(ppv_m2) <- as.character(neue_Filme$budget_log10)
```



Vom breiten ins lange Format √ºberf√ºhren:

```{r}
ppv_m2_long <- 
  ppv_m2 %>% 
  pivot_longer(everything(),
               names_to="budget_log10",
               values_to="rating")
```


Ein paar Erkl√§rungen zu `pivot_wider()`:

- [Bild](https://ab604.github.io/docs/coding-together-2019/img/pivot_wider_R.png)
- [Beispiel](https://www.r-bloggers.com/2019/10/data-pivoting-with-tidyr/)
- [Erkl√§rung](https://dcl-wrangle.stanford.edu/pivot-basic.html)
- [R4DS](https://r4ds.had.co.nz/tidy-data.html)




```{r}
ppv_m2_long %>% 
  ggplot(aes(x = budget_log10,
             y = rating)) +
  geom_boxplot() 
```

Tja, keine gro√üen Unterschiede zwischen den Budget-Faktoren (also den Werte von `budget_log10`). Unser Modell prognostiziert die Daten ganz passabel. Nicht, dass das Ergebnis spektakul√§r w√§re.




### 90%-Vorhersage-Intervalle

Mit der Funktion `predictive_interval` kann man sich obige Berechnung sparen, sondern bekommt sie genussfertig nach Hause.

Wir sehen hier die *tats√§chlichen Rating-Werte* pro Budget-Wert, nicht nur $\mu|b$.




```{r}
post2_pred <- 
  predictive_interval(post2,
                      newdata=neue_Filme)

post2_pred
```


Wie man sieht, sind die Intervalle sehr gro√ü: Das Modell ist *sehr* schlecht.



# Fazit


Die Forschungsfrage war, ob das Budget eines Films mit der Bewertung zusammenh√§ngt.

Dazu wurden zwei einfache lineare Modelle berechnet, die sich in ihren Vorannahmen leicht unterschieden.


## Sch√§tzbereiche f√ºr $\beta$ 

Beide Modelle fanden konsistent einen schwachen, negativen linearen Zusammenhang $\beta$ zwischen Budget und Bewertung: Filme mit mehr Budget wurden konsistent schlechter bewertet, laut den beiden Modellen. 
Hier sind 90%-PI berichtet:

- Modell 1: [`r round(posterior_interval(post1)[2,1], 2)`, `r round(posterior_interval(post1)[2,2], 2)`]
- Modell 2: [`r round(posterior_interval(post2)[2,1], 2)`, `r round(posterior_interval(post2)[2,2], 2)`]



## Medianer Effekt


- Modell 1: `r round(summary(post1)[2,1], 2)`
- Modell 2: `r round(summary(post2)[2,1], 2)`



## Beantwortung der Forschungsfrage


Das Modell ist √ºberzeugt, dass es einen leichten, negativen Zusammenhang gibt. Das Modell schlie√üt aus, dass es *keinen* Zusammenhang gibt.





