---
title: "Fallstudie 'Filmbewertungen'"
author: "ses"
date: "`r Sys.time()`"
output: 
  html_document:
    toc: TRUE
    number_sections: TRUE
editor_options: 
  chunk_output_type: console
---

# Vorbereitung

```{r global-knitr-options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H',
  fig.asp = 0.618,
  fig.width = 5,
  fig.cap = "", 
  out.width = "50%",
  fig.path = "",
  fig.align = "center",
  fig.show = "hold",
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = FALSE)
```


## R-Pakete 

```{r message=FALSE}
library(rstanarm)  # Bayes-Modelle
library(tidyverse)  # Datenjudo
library(bayesplot)  # Plotting
library(gt)  # Tabellen
library(parallel)  # Turbo
library(rstatix)  # Deskriptive Statistiken
library(bayestestR)  # Vernachl√§ssigbare Unterschiede/Zusammenh√§nge
#library(see)  # Visualisierung
library(tictoc)  # Zeit messen, wie lange das Modell rechnet
```



Turbo einschalten:

```{r}
options(mc.cores = parallel::detectCores())
```



## Daten: Filmbeurteilung


```{r}
library(ggplot2movies)
data(movies)
```

Hilfe zu den Daten gibt es hier:

```{r eval = FALSE}
help(movies)
```



# Hintergrund


## Bezug zum Studiengang AWM

Nach dem Studium haben Sie bei einem Online-H√§ndler angeheuert und zwar in der Medien-Abteilung. 
Der Hinweis, dass Sie etwas mit Medien studiert haben gen√ºgte. 
Vielleicht war auch die Behauptung, dass Sie der absolute R-Checker seien n√ºtzlich, 
um den Job zu bekommen ... 
Jedenfalls m√ºssen Sie den Behauptungen Taten folgen lassen, Schluck!



## Forschungsfrage

*Wie (stark) ist der Zusammenhang von logarithmierten Budget und Bewertung eines Films?*

Unser Kunde -- ein reicher M√§zen mit extremen Lebenswandel, 
der gerne ein paar Millionen investieren m√∂chte -- geht von einem positivem Zusammenhang, $\beta$ aus. 
Entsprechend sei unsere Hypothese $H_1: \beta > 0$.


# Explorative Analyse


## Datensatz vorverarbeiten 

Es macht f√ºr Analysen, die in Stan laufen, grunds√§tzlich Sinn:

- nur die relevanten Variablen in die Analyse aufzunehmen
- fehlende Werte zu entfernen
- vorab (vor dem Modellieren) etwaige Transformationen (wie Quadrieren, logarithmieren) vorzunehmen 
- UV und AV zu z-standardisieren

```{r}
movies <-
  movies %>% 
  mutate(budget_log10 = log10(budget))

movies2 <-
  movies %>% 
  select(budget_log10, rating) %>% 
  drop_na() %>% 
  filter(budget_log10 != -Inf)
```


Einige Filme haben ein Budget von 0. 
Das Logarithmus von 0 ist aber minus Unendlich. Mit dieser "Zahl" kann man nicht rechnen. 
Daher filtern wir alle Zeilen mit `-Inf` heraus.


Eine Standardisierung der Pr√§diktoren k√∂nnte n√ºtzlich sein,
ist hier aber nicht weiter ausgef√ºhrt.


## Logarithmus

`budget_log10` fasst die Gr√∂√üenordnung des Budgets:

- 1000: 10^3 -> log10(10^3) = 3
- 10000: 10^4 -> log10(10^4) = 4
- 100000: 10^5 -> log10(10^5) = 5

Wir modellieren also die Gr√∂√üenordnung, nicht den Betrag selber.




## Deskriptive Statistiken


```{r}
movies2 %>% 
  get_summary_stats() %>% 
  gt()
```

Die Umrechung (im Kopf) von logarithmierten Werten ist nicht ganz einfach,
daher hier nochmal die urspr√ºnglichen, nicht-transformierten Werte:

```{r}
movies %>% 
  select(budget, rating) %>% 
  get_summary_stats(type = "mean_sd")
```



## Zusammenhang im Datensatz visualisieren

```{r}
plot0 <- movies %>% 
  ggplot(aes(x = budget_log10, y = rating)) +
  geom_point(alpha = .2)

plot0 +
  geom_smooth(method = "lm")
```
Es scheint  einen sehr schwachen, *negativen* Zusammenhang zu geben.

Das gef√§llt unserem Auftraggeber nicht.

Aber, sagt er, und das zu Recht, entscheidend ist ja nicht die Stichprobe, 
sondern die Population. 
Weswegen wir uns bitte sch√∂n sofort an die Inferenzstatistik bewegen sollten.

Aha, unser M√§zen kennt sich also sogar mit Statistik aus.


# Modelldefinition






## Likelihood

- $r_i \sim N(\mu_i, \sigma)$

mit $r_i$: Rating f√ºr Film $i$

## Lineares Modell


- $\mu_i = \alpha + \beta_1 b$


## Prioris

Die Prioriwerte sind etwas weiter unten aufgef√ºhrt.



# Modell in R

## Modell 1: Standard-Priors (`post1`)

### Modellefinition in R (rstanarm)

```{r compute-post1}
tic()
post1 <- stan_glm(rating ~ budget_log10,
               data = movies2,
               refresh = 0   # Mit `refresh = 0` bekommt man nicht so viel Ausgabe
               )  
toc()
```


Einige Infos zu den Priori-Werten bei `stan_glm()` 
findet sich [hier](https://cran.r-project.org/web/packages/rstanarm/vignettes/priors.html).

Einen √úberblick zu allen Funktionen (R-Befehlen) aus `rstanarm` findet sich √ºbrigens [hier](https://mc-stan.org/rstanarm/reference/index.html).

`tic()` und `toc()` messen Anfang und Ende der dazwischen liegenden Zeit. 
Da die Modelle ein paar Sekunden brauchen, 
ist es ganz interessant zu wissen, wie lange wir warten mussten.


### Priors

Welche Priori-Werte wurden (per Standard) gew√§hlt?

```{r}
prior_summary(post1)
```


Mit `coefficients` ist das Regressionsgewicht $\beta$ gemeint.


Das sind keineswegs besonders schlaue Prioris. 
K√∂nnten wir unseren M√§zen befragen, er scheint ja Experte zu sein, 
k√§men wir vielleicht zu kl√ºgeren Prioris 
(allerdings ist der M√§zen gerade auf einer "Musen-Reise" und nicht zu sprechen).


### Posteriori-Verteilung

√úberblick √ºber die Parameter:

```{r}
print(post1)
```


Langfassung:

```{r}
summary(post1)
```


Nur die mittleren Sch√§tzwerte f√ºr die Regression:

```{r}
coef(post1)
```


Man kann sich die Posteriori-Intervalle so ausgeben lassen:

```{r}
posterior_interval(post1) %>% 
  round(2)
```

Wir wissen jetzt also schon das Wesentliche: 
Mit einer Wahrscheinlichkeit von 90% liegt der Zusammenhang (das Beta-Gewicht) 
f√ºr Log-Budget zwischen -0.13 und -0.07. 
Es gibt also einen gewissen, 
negativen Zusammenhang zwischen Budget und Bewertung eines Films, 
laut unserem Golem zumindest.


### Visualisieren von `post1`


#### Priori-Verteilung



```{r compute-post1-prior-pred, echo = TRUE, eval = TRUE}
post1_prior_pred <- stan_glm(rating ~ budget_log10,
               data = movies2,
               prior_PD = TRUE  # DIESER Schalter gibt uns die Prior-Pr√§diktiv-Verteilung
               #, refresh = 0
               )  # Mit `refresh = 0` bekommt man nicht so viel Ausgabe
```



Aus der [Hilfeseite](https://www.rdocumentation.org/packages/rstanarm/versions/2.21.1/topics/stan_glm):

`prior_PD    A logical scalar (defaulting to FALSE) indicating whether to draw from the prior predictive distribution instead of conditioning on the outcome.`

```{r}
post1_prior_pred
```


Die Koeffizienten aus `post1_prior_pred` sind also *rein* durch die Priori-Werte definiert; 
die Daten sind nicht eingeflossen.


Wenn wir das Objekt mit `as_tibble()` in eine Tabelle umwandeln, 
bekommen wir eine Tabelle mit den Stichproben:

```{r}
post1_prior_pred_draws <- 
  post1_prior_pred %>% 
  as_tibble() %>% 
  rename(a = `(Intercept)`,  # sch√∂nere, einfachere Namen
         b = budget_log10) %>% 
  slice_sample(n = 100)
```



```{r prior-post1-plot, echo = TRUE, eval = TRUE}
movies2 %>% 
  ggplot() +
  geom_point(aes(x = budget_log10, y = rating)) + 
  geom_abline(data = post1_prior_pred_draws,
aes(intercept = a, slope = b), color = "skyblue", size = 0.2)

```


Puh, die Priori-Werte sind ... vogelwild üê¶.




#### Posteriori-Verteilung: Regressionsgerade 

```{r}
plot1 <- plot0 +
  geom_abline(intercept = coef(post1)[1],
              slope = coef(post1)[2],
              color = "blue")
plot1
```


```{r}
col_names <- c("a", "b", "sigma")
draws_m1 <-
  post1 %>% 
  as_tibble() 

names(draws_m1) <- col_names
```

Ein Blick in die ersten paar Zeilen der Post-Stichproben:

```{r}
draws_m1 %>% 
  slice_head(n=10) %>% 
  gt() %>% 
  fmt_number(everything(), decimals = 1)
```


Und hier die Posteriori-Verteilung f√ºr $\alpha$ und $\beta$ visualisiert:

```{r}
plot0 +
  geom_abline(data = draws_m1,
              aes(intercept = a,
                  slope = b),
              color = "skyblue1",
              alpha = .1) +
  geom_abline(intercept = coef(post1)[1],
              slope = coef(post1)[2],
              color = "blue")
```





#### Verteilung von $\beta$


Hier die Verteilung f√ºr die Steigung (Regressionsgewicht $\beta$):

```{r}
draws_m1 %>% 
  ggplot(aes(x = b)) +
  geom_density()
```


#### Posterior-Intervalle



Die Posteriori-Intervalle kann man sich schn√∂de mit `plot()` ausgeben lassen, 
wobei man als Parameter den Namen des Modells √ºbergibt.

```{r}
plot(post1)
```


Es gibt aber auch andere Darstellungsarten, z.B. als Dichtediagramme:


```{r}
mcmc_areas(post1) +
  labs(title = "Posteriori-Verteilung",
       caption = "Gezeigt werden Median und 50% bzw. 90% Perzentil-Intervalle")
```

S. [Hilfe hier](https://mc-stan.org/bayesplot/reference/MCMC-intervals.html)


Man kann sich auch angeben, welchen Parameter man visualisieren m√∂chte, 
und zwar mit dem Argument `pars` (wie *parameters*).


Oder nur das Posteriori-Interval f√ºr den Regressionskoeffizienten:

```{r}
mcmc_areas(post1,
           pars = "budget_log10")
```


### Fazit


Die Wahrscheinlichkeit, dass der Zusammenhang in Wirklichkeit zwischen -0.15 und -0.05 ist, 
ist sehr hoch.

Aber was bedeutet das, wie interpretiert man den Befund?

Rufen wir uns dazu ins Ged√§chtnis, was log10 bedeutet: 
Es bedeutet, dass man das Budget mit 10 multipliziert, also verzehnfacht, sozusagen eine Null hintendran schreibt.

Also: *Verzehnfacht man das Budget, so verringert sich mittlere Bewertung um etwa 0.15 bis 0.05 Punkte.*

Ob das viel ist, muss ein Medienexperte beantworten. 
Vielleicht sind Sie ja einer!


## Modell 2: Informierte (?) Priors

Kramen wir all unser Wissen √ºber Filme und die Filmindustrie zusammen! 
Wie wichtig sind die Kohlen f√ºr die G√ºte eines Films? Haben die einen gro√üen Einfluss? 

(Wenn wir von "Einfluss" sprechen, denken wir sicher automatisch an *kausalen* Einfluss. 
Jedenfalls geht es mir so und ich glaube, es ist schwierig, nicht an kausalen Einfluss, sondern nur an blanke Assoization, zu denken).


### Modellefinition in R (rstanarm)


Au√üerdem z-standardisieren wir jetzt UV und AV.

```{r}
movies3 <- 
  movies2 %>% 
  transmute(budget_log10_z = scale(budget_log10),
            rating_z = scale(rating))
```



Nach langem Beratschschlagen mit Film-Experten gehen wir davon aus, 
dass es im Prinzip - "normalerweise" keinen Zusammenhang gibt. 
Allerdings hat man in Filmen schon Pferde kotzen gesehen, 
deswegen wollen wir unseren Golem zu verstehen geben, 
dass er sich auch auf √úberraschungen einstellen soll ...
(Schlie√ülich wurden wir, oder zumindest unser M√§zen gerade selber von den Daten √ºberrascht.) 

Kurz gesagt, wir definieren $\beta$ so, auf Golem-Sprech:

$$\beta = \mathcal{N}(0,0.2)$$


Bei z-standardisierten Variablen in einem einfachen Regressionsmodell 
kann $\beta$ wir $\rho$ (Korrelation) interpretiert werden.

Oben formulierter Prior ist also der Meinung.

*Es gibt eine schwache ($r=0.2$) Korrelation*
*zwischen Verzehnfachung des Budgetsund der Filmbewertung*.

Mit anderen Worten, ein Unterschied von einer SD im Log-Budget 
geht mit einer Ver√§nduerng von (in 95% der F√§lle) nicht mehr als ¬±0.4 Rating-Punkte einher.

Ein Nachteil der z-Standardisierung ist die schwierigere Interpretation;
daher ist die Zentrierung in einigen F√§llen die bessere Transformation.
Bei der Zentrierung bleiben die Einheiten (wie Dollar) erhalten,
was oft w√ºnschenswert ist.
Sind die Eiheiten aber wenig "sprechend" (z.B. Punkte auf einer Fragebogenskala),
so verliert man wenig, wenn man die Roh-Einheiten mit der z-Transformation aufgibt.

F√ºr die √ºbrigen Priorwerte greifen wir auf wenig ambitionierte Standardwerte zur√ºck.



`transmute()` ist wie `mutate()`, nur dass nur die transformierten Variablen
im Datensatz behalten werden, alle √ºbrigen Variablen werden entfernt.



```{r compute-post2}
tic()
post2 <- stan_glm(rating_z ~ budget_log10_z,
               data = movies3,
               prior = normal(0, .2),  # beta
               refresh = 0)  # Nicht so viel Ausgabe
toc()
```


Ein "Gef√ºhl" zur Exponentialverteilung zu entwickeln, 
ist nicht so einfach wie bei der Normalverteilung, da
weniger gebr√§uchlich.

Es hilft, sich die Quantile `q` der `exp`onentialverteilung anzuschauen, 
hier die "Standardverteilung" mit der Rate 1:

```{r}
qexp(p = .95, rate = 1)
```


Die Ausgabe sagt uns, dass 95% der Beobachtungen einen Wert kleiner als ca. 3 haben.

Auf unsere Fallstudie bezogen:
Wir erwarten, dass 95% der Werte h√∂chstens 3 Einheiten der AV vom 
vorhergesagten Wert entfernt sind.
Das ist ziemlich lax (schwach informativ),
denn unsere AV ist z-skaliert.



Um Rechenzeit zu sparen, kann man das Modell auch speichern:

```{r eval = FALSE}
save(post1, file = "post2.rda")
load(file = "post2.rda")
```


### Priors

Hier ein √úberblick der Priors, 
die unser Modell `post2` verwendet:

```{r}
prior_summary(post2)
```



### Prior-Pr√§diktiv-Verteilung

#### Berechnen der Prior-Pr√§diktiv-Verteilung

```{r compute-post2-prior-pred}
tic()
post2_prior_pred <- stan_glm(rating_z ~ budget_log10_z,
                             data = movies3,
                             prior_PD = TRUE,  # Prior-Pr√§diktiv-Verteilung
                             prior = normal(0, .2),  # beta
                             refresh = 0)  # Nicht so viel Ausgabe
toc()
```



#### Visualisierung der Prior-Pr√§diktiv-Verteilung

Dazu gehen wir vor wie f√ºr Modell 1, `post1`. 
Zuerst wandeln wir das Objekt `post2` in eine Tabelle mit den Stichproben aus der Post-Verteilung um:

```{r}
post2_prior_pred_draws <- 
  post2_prior_pred %>% 
  as_tibble() %>% 
  rename(a = `(Intercept)`,  # sch√∂nere, einfachere Namen
         b = budget_log10_z) %>% 
  slice_sample(n = 100)
```


Und dann visualisieren



```{r prior-post2-plot, echo = TRUE, eval = TRUE}
movies3 %>% 
  ggplot() +
  geom_point(aes(x = budget_log10_z, y = rating_z)) + 
  geom_abline(data = post2_prior_pred_draws,
              aes(intercept = a, slope = b), color = "skyblue", size = 0.2)
```


Sieht doch schon viel besser aus. üèÜ


### Posteriori-Verteilung


#### Kurzfassung

√úberblick √ºber die Parameter:

```{r}
print(post2)
```


Nur die mittleren Sch√§tzwerte f√ºr die Regression:

```{r}
coef(post2)
```


#### Langfassung

Ausf√ºhrlicher:

```{r}
summary(post2)
```


### Visualisieren von `post2`


#### Regressionsgerade 

```{r}
plot0_z <- movies3 %>% 
  ggplot(aes(x = budget_log10_z, y = rating_z)) +
  geom_point(alpha = .2)
```


```{r}
plot1_m2 <- 
  plot0_z +
  geom_abline(intercept = coef(post2)[1],
              slope = coef(post2)[2],
              color = "blue")
plot1_m2
```

Erstellen wir eine Tabelle nur mit den Post-Samples:

```{r}
col_names <- c("a", "b", "sigma")
draws_m2 <-
  post2 %>% 
  as_tibble() 

names(draws_m2) <- col_names
```

Die ersten paar Werte aus der Tabelle mit Post-Samples:

```{r echo = FALSE}
draws_m2 %>% 
  slice_head(n=10) %>% 
  gt() %>% 
  fmt_number(everything(), decimals = 1)
```

Und hier die Regressionsgerade mit dem "Unsicherheitsbereich" 
f√ºr die Regressionskoeffizienten.

```{r}
plot0_z +
  geom_abline(data = draws_m2,
              aes(intercept = a,
                  slope = b),
              color = "skyblue1",
              alpha = .1) +
  geom_abline(intercept = coef(post2)[1],
              slope = coef(post2)[2],
              color = "blue")
```

#### Verteilung von $\beta$


```{r}
draws_m2 %>% 
  ggplot(aes(x = b)) +
  geom_density()
```


#### Posterior-Intervalle

S. [Hilfe hier](https://mc-stan.org/bayesplot/reference/MCMC-intervals.html)

```{r}
mcmc_areas(post2) +
  labs(title = "Posteriori-Verteilung",
       caption = "Gezeigt werden Median und 50% bzw. 90% Perzentil-Intervalle")
```


```{r}
mcmc_intervals(post2,
               pars = "budget_log10_z") 
```



```{r}
mcmc_areas(post2,
           pars = "budget_log10_z") +
  labs(title = "Posteriori-Verteilung",
       caption = "Gezeigt werden Median und 50% bzw. 90% Perzentil-Intervalle")
```

Das ist das Gleiche wie unser Dichte-Diagramme etwas weiter oben.

### Quantile

```{r}
summary(post2)
```

Laut dem Modell (`post2`) liegt der Regressionskoeffizient mit 90% Wahrscheinlichkeit 
eng um -0.1 herum.

Genauer gesagt: $90\%PI_b: (-0.13, -0.07)$:

```{r}
draws_m2 %>% 
  summarise(b_90pi = quantile(b, probs = c(0.05, .95)))
```

```{r}
posterior_interval(post2)
```


### Wahrscheinlichkeiten f√ºr Parameterwerte

#### Positiver Zusammenhang

$p(b > 0|D)$

mit "D", den Daten des Modells.

```{r}
draws_m2 %>% 
  count(b > 0)
```


Die Wahrscheinlichkeit ist praktisch Null, 
dass der Zusammenhang positiv ist.



### $R^2$


```{r}
tic()
post2_r2 <- 
  bayes_R2(post2) %>% 
  as_tibble()
toc()
```


```{r}
post2_r2 %>% 
  ggplot(aes(x=value)) +
  geom_density()
```


```{r}
post2_r2 %>% 
  summarise(r2_mean = mean(value),
            r2_median = median(value))
```
Der Anteil erkl√§rter Varianz ist praktisch Null.


Der Golem blickt es nicht! Das Modell ist schlecht. 


### Verh√§ltnis von Prior zu Posteriori

Ein interessanter Blick ist der Vergleich der Priori- zu Posteriori-Verteilungen:
Um wieviel hat sich unsere Einsch√§tzung (von Priori zu Posteriori) durch die Daten ge√§ndert?

Das kann man sich gut so visualisieren lassen:

```{r}
posterior_vs_prior(post2)
```


Wir sehen, dass sich die zentrale Tendenz der Parameter (von Prior zu Posterior)
kaum ge√§ndert hat: Die "Lage" ist fast gleich.
Allerdings hat sich die Ungewissheit (des Golems) drastisch verringert.
Ob wir seiner Meinung folgen,
steht auf einem anderen Blatt: Seine Meinung bezieht sich ausschlie√ülich
auf seine kleine Welt.
Er wei√ü nichts von der Welt au√üer den Informationen, 
die wir ihm gegeben haben.
Wir dagegen vermuten vermutlich,
dass noch andere Dinge eine Rolle spielen au√üer dem Budget,
wenn es darum geht, die Beliebtheit eines Films vorherzusagen.





### PPV

#### PPV berechnen

Simulieren wir den Erfolg neuer Filme; dabei betrachten wir das Budget von $10^3$ bis $10^8$ (6 Werte). 
Wir ziehen pro Budgetwert 1000 Stichproben aus der PPV.

```{r}
neue_Filme <- 
  tibble(
    budget_log10_z = 3:8)
```


Warum `3` bis `8`? Das sind genau die Werte f√ºr `budget_log10`, die wir in daten Daten haben.

Wie viel delogarithmiertem, also "richtigem" Budget entspricht das?

```{r}
10^(3:8)
```

- $10^3 = 1,000$
- $10^4 = 10,000$
- ...
- $10^8 = 100,000,000$


```{r}
ppv_m2 <- 
  posterior_predict(post2, neue_Filme, draws = 1e3) %>% 
  as_tibble() 


dim(ppv_m2)  # Zeilen, Spalten
```


Leider werden unsere Eingabewerte (3 bis 8) zerhauen, stattdessen wird 1 bis 6 zur√ºckgegeben. 
K√ºmmern wir uns gleich darum.


Hier ein Blick in die Tabelle `ppv_m2`: 

```{r echo = FALSE}
ppv_m2 %>% 
  head() %>% 
  gt() 
```

√Ñndern wir die Spaltennamen von 1,2,...6, in 3,4,...,8 um.

Reine Zahlen werden als Spaltennamen nicht akzeptiert, 
deswegen wandeln wir noch die Zahl `3` in den Text `"3"` um, mit `as.character()`: 

```{r}
names(ppv_m2) <- as.character(neue_Filme$budget_log10_z)
```



Vom breiten ins lange Format √ºberf√ºhren:

```{r}
ppv_m2_long <- 
  ppv_m2 %>% 
  pivot_longer(everything(),
               names_to="budget_log10_z",
               values_to="rating")
```


Ein paar Erkl√§rungen zu `pivot_wider()`:

- [Bild](https://ab604.github.io/docs/coding-together-2019/img/pivot_wider_R.png)
- [Beispiel](https://www.r-bloggers.com/2019/10/data-pivoting-with-tidyr/)
- [Erkl√§rung](https://dcl-wrangle.stanford.edu/pivot-basic.html)
- [R4DS](https://r4ds.had.co.nz/tidy-data.html)




```{r}
ppv_m2_long %>% 
  ggplot(aes(x = budget_log10_z,
             y = rating)) +
  geom_boxplot() 
```

Tja, keine gro√üen Unterschiede zwischen den Budget-Faktoren (also den Werte von `budget_log10`). 
Unser Modell prognostiziert die Daten ganz passabel. Nicht, dass das Ergebnis spektakul√§r w√§re.




### 90%-Vorhersage-Intervalle

Mit der Funktion `predictive_interval` kann man sich obige Berechnung sparen, 
sondern bekommt sie genussfertig nach Hause.

Wir sehen hier die *tats√§chlichen Rating-Werte* pro Budget-Wert, nicht nur $\mu|b$.




```{r}
post2_pred <- 
  predictive_interval(post2,
                      newdata=neue_Filme)

post2_pred
```


Wie man sieht, sind die Intervalle sehr gro√ü: Das Modell ist *sehr* schlecht.


## Modell 3

Schauen wir uns noch mal,
was es eigentlich f√ºr Pr√§diktoren gibt 
bzw. zur Auswahl stehen:

```{r}
movies %>% 
  select(-starts_with("r")) %>% 
  get_summary_stats(type = "robust") %>% 
  gt()
```


Dabei f√§llt auf,
dass nur (relativ) gesehen sehr wenige Filme
eine Info zum Budget haben.
Unsere Modell mit `budget` haben also nur einen geringen Teil
der Stichprobe verwendet.

Unser M√§zen schl√§gt vor,
die Variable `Action` zu untersuchen.
Aus seiner Sicht sind Achtionfilme zumeist Mist.
Er steht auf `Drama`, wie er uns berichtet. Aha.

Nehmen wir die Meinung des M√§zens als Ersatz
f√ºr eine fundierte Literaturrecherche und untersuchen seine Hypothese:
Wenn ein Film vom Typ `Action` ist,
dann wird er im Schnitt schlechter beurteilt.


```{r}
movies4 <-
  movies %>% 
  mutate(rating_z = scale(rating)) %>% 
  select(rating_z, Action) %>% 
  drop_na()
```

```{r}
nrow(movies4) / nrow(movies)
```


Ah! Mit diesen Variablen haben wir kaum Beobachtungen eingeb√º√üt.


```{r}
post3 <-
  stan_glm(rating_z ~ Action,
           data = movies4,
           refresh = 0)
```

```{r}
posterior_interval(post3)
```


Ah! Das sieht ganz gut aus.

Unser M√§zen hatte vielleicht einen ganz guten Riecher. 
`Action` scheint einen Einfluss auf das Rating zu haben (zumindest deskriptiv betrachtet).



# Modellvergleich

```{r}
modelle <-
  tibble(
    id = 1:3,
    sigma_modell = c(
      sigma(post1),
      sigma(post2),
      sigma(post3)
    ),
    r2_modell = c(
      median(bayes_R2(post1)),
      median(bayes_R2(post2)),
      median(bayes_R2(post3))
    )
  )

modelle %>% 
  gt() %>% 
  fmt_number(where(is.numeric), decimals = 2)
```




# Fazit


Die Forschungsfrage war, ob das Budget eines Films mit der Bewertung zusammenh√§ngt.

Dazu wurden zwei einfache lineare Modelle berechnet, 
die sich in ihren Vorannahmen leicht unterschieden.


## Sch√§tzbereiche f√ºr $\beta$ 

Beide Modelle fanden konsistent einen schwachen, 
negativen linearen Zusammenhang $\beta$ zwischen Budget und Bewertung: 
Filme mit mehr Budget wurden konsistent schlechter bewertet, 
laut den beiden Modellen. 

Hier sind 90%-PI berichtet:

- Modell 1: [`r round(posterior_interval(post1)[2,1], 2)`, `r round(posterior_interval(post1)[2,2], 2)`]
- Modell 2: [`r round(posterior_interval(post2)[2,1], 2)`, `r round(posterior_interval(post2)[2,2], 2)`]



## Medianer Effekt


- Modell 1: `r round(summary(post1)[2,1], 2)`
- Modell 2: `r round(summary(post2)[2,1], 2)`



## Beantwortung der Forschungsfrage


Das Modell ist √ºberzeugt, dass es einen leichten, 
negativen Zusammenhang gibt. Das Modell schlie√üt aus, 
dass es *keinen* Zusammenhang gibt.

## Limitationen

Die Grenzen dieser Analyse sind vielschichtig.
Ein Hauptprobleme ist sicherlich, dass wir nur einen Pr√§diktor verwendet haben,
um einen Eindruck von der "Relevanz" des Pr√§diktors zu bekommen.
Dabei ist "Relevanz" wahrscheinlich bereits ein kausales Wort -
und ohne ein Kausalmodell k√∂nnen wir √ºber kausale Gegebenheiten keine Schl√ºsse ziehen.
Es bleibt uns der, eher unbefriedigende *deskriptive* Schluss,
dass es einen schwachen, negativen, linearen Zusammenhang zwischen den beiden Gr√∂√üen gibt -
laut diesem Modell. Es darf nicht vergessen werden,
dass sich der Zusammenhang √§ndern kann (und es in vielen F√§llen auch tun wird),
wenn wir das Modell ver√§ndern, z.B. weitere Pr√§diktoren dem Modell hinzuf√ºgen.

Ein komfortabler Ausweg ist oder w√§re es, 
sich auf Vorhersagen zu begrenzen. Daf√ºr sind Kausalmodelle nicht zwingend 
(aber auch nicht verkehrt).

Ein weiterer Kritikpunkt k√∂nnte die Wahl unserer Prior sein.
Allerdings waren unsere Priors nur schwach informativ,
so dass sie wenig Einfluss auf die Posteriori-Verteilung hatten.



# SessionInfo

```{r}
sessioninfo::session_info()
```





