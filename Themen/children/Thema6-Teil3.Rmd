```{r}
library(tidyverse)
library(gt)
library(rstanarm)
library(rstatix)
library(ggridges)
```


name: teil-3
class: middle, center

# Teil 3

## Eine nominale UV mit mehreren Stufen

---


## Forschungsfrage

*Hintergrund*:

Nach Ihrem Studium haben Sie bei einem aufstrebenden Online-H√§ndler angeheuert
Sie sind f√ºr alles zust√§ndig, 
was nach Wissenschaft oder Analyse aussieht oder sonst den Anschein erweckt,
kompliziert zu sein. 
Aus irgendwelchen Gr√ºnden liebt Ihre Chefin Diamanten,
so dass Ihre erste Aufgabe darin besteht, Diamantenpreise zu analysieren. 
Das Ziel Ihrer Chefin liegt darin, 
zu erkennen, was ein Preis ist, 
f√ºr den ein Diamant gut verkauft werden kann. Kennt man diesen Preis, 
kann man sich auf die Suche machen, 
ob man den Diamant irgendwo g√ºnstiger findet. 
Wenn ja, macht man Gewinn. 
Gutes Gesch√§ftsmodell, meint Ihre Chefin.

</br>


> Unterscheiden sich mittlere Diamantenpreise in Abh√§ngigkeit von ihrer Schliffart? (Datensatz `diamonds`)




---

## Alle Mittelwerte sind gleich (?)

- Formal: $\mu_1 = \mu_2 = \ldots = \mu_k$ mit $k$ verschiedenen Gruppen von Schliffart.

- Hypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als *Nullhypothesen* bezeichnen.

- Moment. Dass sich *alle* Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? ü§î Daher ist die bessere Forschungsfrage:

> *Wie sehr* unterscheiden sich mittlere Diamantenpreise in Abh√§ngigkeit von ihrer Schliffart?

Oder wir pr√ºfen die Hypothese, ob die Mittelwerte "praktisch" gleich sind, also sich "kaum" unterscheiden. Der Grenzwert f√ºr "praktisch gleich" bzw. "kaum unterschiedlich" ist subjektiv.

---

## Erster Blick in den Datensatz `diamonds`

[Datenquelle](https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/diamonds.csv), [Beschreibung des Datensatzes](https://vincentarelbundock.github.io/Rdatasets/doc/ggplot2/diamonds.html)

```{r echo = TRUE}
diamonds_url <- "https://tinyurl.com/up84jp5c"
```

```{r echo = TRUE, results = "hide"}
set.seed(42)  # Zufallszahlen f√ºr `sample()` festlegen
diamonds <- 
  read_csv(diamonds_url) %>% 
  sample_n(1000) %>%  # um etwas Rechenzeit zu sparen
  select(-1) # 1. Spalte nur laufende Nummer
```

```{r echo = TRUE, eval = FALSE}
diamonds %>% 
  select(price, cut) %>% 
  group_by(cut) %>% 
  # nehmen wir die robusten Statistiken, da Preis sehr schief ist:
  get_summary_stats(type = "robust")
```




---

## Ein √úberblick √ºber die metrischen Variablen



... aufgeteilt in die Stufen von `cut`:

```{r echo = FALSE, eval = TRUE}
diamonds %>% 
  select(price, cut) %>% 
  group_by(cut) %>% 
  # nehmen wir die robusten Statistiken, da Preis sehr schief ist:
  get_summary_stats(type = "robust") %>% 
  gt() %>% 
  fmt_number(3:last_col(), decimals = 1)
```


Was f√§llt Ihnen auf?

---

## Visualisierung (EDA)


.pull-left[

```{r}
diamonds %>% 
  drop_na(cut, price) %>% 
  group_by(cut) %>% 
  summarise(price_md =
              median(price),
            price_iqr = 
              IQR(price)) %>%
  gt() %>% 
  fmt_number(columns = 2:3,
             decimals = 0)
```


]

.pull-right[
```{r}
diamonds %>% 
  ggplot(aes(x=cut, y=price)) +
  geom_boxplot()
```

]
```{r fig.asp = .3, fig.width=7}
ggplot(diamonds) +
  aes(x = price, y = cut) +
  geom_density_ridges()
```



---

## Mittlere Preisunterschiede in der Population



```{r m106, echo = TRUE}
options(mc.cores = parallel::detectCores())  # Turbo einschalten

m10.6 <- stan_glm(price ~ cut, data = diamonds, refresh = 0)
# refresh=0 unterdr√ºckt Ausgabe der Posteriori-Stichproben
```



```{r}
m10.6
```

---


## Interpretation von `m10.6`

- `cut` hat f√ºnf verschiedene Werte (Stufen, Faktorstufen, Auspr√§gungen), aber es werden nur vier angezeigt. 
- Die f√ºnfte (`Fair`, nicht ausgegeben) ist die *Vergleichs- oder Referenzkategorie* (baseline) und ist im Achsenabschnitt ausgedr√ºckt.
- Die Koeffizienten f√ºr `cut` geben jeweils den Unterschied zur Vergleichskategorie wieder.
- Diamanten der Schliffart `Fair` haben laut Modell einen mittleren Preis von ca. 4300$.
- Diamanten der Schliffart `Good` sind laut Modell im Mittel gut 400$ billiger als Diamanten der Schliffart `Fair`, etc.


```{r fig.asp = .33}
plot(m10.6, regex_pars = "^cut")
```

---


## Sch√§tzbereiche (PI) f√ºr die Modellparameter

```{r echo = TRUE}
m10.6_post <-
  m10.6 %>% 
  as_tibble()

grenzen <- c(0.025, 0.975)

m10.6_post %>% 
  summarise(pi_intercept = quantile(`(Intercept)`, probs = grenzen),
            cutGood = quantile(cutGood, probs = grenzen),
            cutIdeal = quantile(cutIdeal, probs = grenzen),
            cutPremium = quantile(cutPremium, probs = grenzen),
            `cutVery Good` = quantile(`cutVery Good`, probs = grenzen))
```

Variablennamen, die nach R-Rechtschreiberegeln verboten sind, wie `cutVery Good` oder `(Intercept`), m√ºssen mit Backticks angef√ºhrt werden:

````
`(Intercept)`
`cutVery Good`
````

---

## Sch√§tzbereiche (PI) ausgeben lassen, komfortabel

Einfacher bekommt man die gleiche Ausgabe z.B. so:
```{r echo = TRUE, eval = TRUE}
posterior_interval(m10.6,
                   prob = .89)
```


.footnote[[Hilfeseite f√ºr diese Funktion](http://mc-stan.org/rstanarm/reference/posterior_interval.stanreg.html)]
---

## 95%-HDI f√ºr die Regressionskoeffizienten

Da die Forschungsfrage nur auf die Regressionskoeffizienten, nicht auf $\sigma$ abzielt, brauchen wir uns $\sigma$ auch nicht en Detail anschauen.

Das HDI kann man komfortabel z.B. so bekommen:

```{r echo = TRUE}
bayestestR::hdi(m10.6)
```

Wie man sieht, sind die Intervallgrenzen des HDI √§hnlich zu denen des PI.

---

## Glauben wir jetzt an Preisunterschiede?

... zwischen den Preis-Mittelwerten in der Population?

- Teilweise, denn einige Sch√§tzintervalle (f√ºr die Preisunterschiede) waren im Modell `m10.6` weit von der Null entfernt, andere nicht.

- Auf Basis unseres Modells schlie√üen wir also (mit hoher Sicherheit) aus, dass *alle* Preise im Mittelwert *exakt* identisch sind.

- Ehrlicherweise h√§tte sowieso niemand geglaubt, dass die *exakte Nullhypothese* $\mu_1 = \mu_2 = \ldots = \mu_k$ bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null.

- Aber: Viele Forscheris pr√ºfen gerne die Nullhypothese, daher taucht der Begriff hier auf.

- Das Verfahren der Frequentistischen Statistik, um die Nullhypothese $\mu_1 = \mu_2 = \ldots = \mu_k$ zu testen, nennt man *Varianzanalyse* (analysis of variance, kurz *ANOVA*).

- In der Bayes-Statistik nutzt man - wie immer - prim√§r die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art) zu inferenzstatistisch zu beurteilen.



---

## Modellkoeffizienten von `m10.6`

Die Regressionsoeffizienten pro Stufen von `cut`entsprechen den Mittelwerten $\hat{y_i}$ aus der Posteriori-Verteilung. Mit `coef(m10.6)` kann man sie sich bequem ausgeben lassen.

```{r echo = TRUE}
coef(m10.6)
```


- $\hat{y}_{Fair} = `r round(coef(m10.6)[1])`$
- $\hat{y}_{Good} = `r round(coef(m10.6)[2])`$
- etc.


---

## Wechsel der Referenzkategorie

- `cut` ist eine nominale Variable, da passt in R der Typ `factor` (Faktor) am besten. Aktuell ist der Typ noch `character` (Text):

```{r echo = TRUE}
diamonds <- diamonds %>% 
  mutate(cut = factor(cut))
```


- Im Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge √§ndern. 

```{r echo = TRUE}
levels(diamonds$cut)
```

Setzen wir `Ideal` als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:

```{r echo = TRUE}
library(forcats)
diamonds <- diamonds %>% 
  mutate(cut = factor(cut),
    cut = fct_relevel(cut, "Ideal"))
```

```{r}
levels(diamonds$cut)
```







---

## Wechsel der Referenzkategorie √§ndert nichts Wesentliches am Modell

```{r echo = TRUE}
m10.6a <- stan_glm(price ~ cut, data = diamonds, refresh = 0)
m10.6a
```



---

## Modellg√ºte mit $R^2$ bestimmen


.pull-left[
- $R^2$ gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erkl√§rt.
- H√∂here Wert von $R^2$ bedeuten, dass das Modell die Daten besser erkl√§rt.
- $R^2$ wird normalerweise auf Basis eines Punktsch√§tzers definiert.
- Solch eine Definition l√§sst aber viel Information - √ºber die Ungewissheit der Sch√§tzung - au√üen vor.
- Daher ist es w√ºnschenswert, diese Information in $R^2$ einflie√üen zu lassen: *Bayes-R-Quadrat*.
- mit `bayes_r2()` kann man sich die Verteilung berechnen lassen.
]

<!-- R^2_{Bayes} = \frac{\text{erkl√§rte Varianz}}{\text{erk√§rte Varianz + Residualvarianz}} = \frac{var_{fit}}{var_{fit}+var_{res}} -->

<!-- - $var_{fit}$ ist die Varianz der vorhergesagten Sch√§tzwerte $\hat{y}_i$. -->


.pull-right[
```{r echo = TRUE}
m10.6_r2 <- bayes_R2(m10.6)
median(m10.6_r2)
IQR(m10.6_r2)
```

```{r}
m10.6_r2 %>% 
  as_tibble() %>% 
  ggplot(aes(x=value)) +
  geom_histogram()
```

]

---

## Definition vom "klassischen" $R^2$




- Wie genau sind die Vorhersagen des Modells? $\sigma$ (Vorhersagefehler) quantifiziert die Streuung der Residuen $r_i = y_i - X_i\hat{\beta}$, mit $\hat{y}_i = X_i\hat{\beta}$. 
- Anders gesagt: $\hat{y} = \beta_0 + \beta_1x_1 + \beta_2x_2 + \cdots = X\hat{\beta}$.
- Anders gesagt gibt $\sigma$ die "typische" Abweichung einer Beobachtung vom vorhergesagten Wert an.
- Es ist n√ºtzlich, $\sigma$ in Bezug zu setzen zur Streuung der AV, $sd_y=s_y$:
- $R^2 = 1- (\hat{\sigma}^2/s^2_y)$.
- $R2$ gibt damit den Anteil der vom Modell erkl√§rten Varianz, $V$, an.
- Berechnet man das Modell mit der Methode der kleinsten Quadrate (nicht mit Bayes), dann ist der obige Ausdruck √§quivalent zu:
- $R^2=V_{i=1}^n \hat{y}_i/s_y^2$
- Die beiden obigen Ausdr√ºcke nehmen $\hat{y}_i$ als fix (sicher) an und vernachl√§ssigen Ungewissheit; sie sind √ºbergewiss aus Bayes-Sicht.


---

## Bayes' $R^2$

- Besser ist es (aus Bayes-Sicht), die Ungewissheit der Vorhersagen bei der Berechnung der Modellg√ºte miteinzubeziehen:
- $\text{Bayes }R^2 = \frac{\text{erk√§rte Varianz}}{\text{Erkl√§rte Varianz + Residualvarianz}}= \frac{V_{mod}}{V_{mod} + V_{res}}$
- $V_{mod}$ ist die Varianz in der PPV mit $s = 1, \ldots, S$ simulierten Stichproben, $V(\hat{y}_i)$ und $V_{res}$ ist die Residualvarianz im Modell.
- F√ºr jede Stichprobe $s$ berechnet man die vorhergesagten Werte, $\hat{y}_i^s$, die Residualvarianz $\sigma^2_s$ und den Anteil der erkl√§rten Varianz:
- $\text{Bayes }R^2_s = \frac{V(\hat{y}_i^s)}{V(\hat{y}_i^s+\sigma_s^2)}$


`r RefManageR::Citep(bib, c( "gelman_r_squared_2019", "gelman_regression_2021"), after = ", Kap. 11.7")`




---

## Priori-Werte

- Unser Modell hat schwach informierte (weakly informative) Priors.
- F√ºr Achsenabschnitt und die Regressionskoeffizienten werden Normalverteilungen angenommen mit Mittelwert entsprechend den Stichprobendaten und Streuung, die der 2.5-fachen der Streuung in der Stichprobe entspricht.
- Mehr Infos kann man sich so ausgeben lassen: `prior_summary(m10.6)`.
- Wo man man √ºber mehr inhaltliches Wissen verf√ºgt, so wird man die Priors anpassen wollen, z.B.:

```{r echo = TRUE}
m10.6b <- stan_glm(price ~ cut, data = diamonds, refresh = 0,
                   prior = normal(location = c(100, 100, 100, 100),
                                  scale = c(100, 100, 100, 100)),
                   prior_intercept = normal(3000, 500))
coef(m10.6b)
sigma(m10.6b)
```




---


## "Praktisch" kein Unterschied



- Sagen wir, wenn sich zwei Preismittelwerte um h√∂chstens $d=100$‚Ç¨ unterscheiden, gilt dieser Unterschied f√ºr uns als "praktisch gleich", "praktisch kein Unterschied" bzw. vernachl√§ssigbar.
- Nimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer *Nullhypothese*: $H_0$.
- Die Wahl von $d$ ist *subjektiv* in dem Sinne als sie von inhaltlichen √úberlegungen geleitet sein sollte.
- Diesen Bereich bezeichnen wir den *Indifferenzbereich* (√Ñquivalenzone, Bereich eines vernachl√§ssigbaren Unterschieds oder *Region of practical equivalence*, Rope). 
- Jetzt pr√ºfen wir, ob ein "Gro√üteil" der Posteriori-Stichproben im Rope liegt.
- Unter "Gro√üteil" wird h√§ufig das *95%-HDI* verstanden.

*Entscheidungsregel*:

- Gro√üteil liegt *innerhalb* von Rope  ‚û°Ô∏è *Annahme* der Nullhypothese "praktisch kein Effekt", $H_0$
- Gro√üteil liegt *au√üerhalb* von Rope  ‚û°Ô∏è *Ablehnung* der Nullhypothese "praktisch kein Effekt", $H_0$
- Ansonsten  ‚û°Ô∏è  keine Entscheidung 

`r RefManageR::Citep(bib, "kruschke_rejecting_2018")`


---

## HDI-Rope-Entscheidungsregel visualisiert

```{r out.width="70%"}
knitr::include_graphics("https://github.com/sebastiansauer/QM2-Folien/raw/main/img/Kruschke-2018-Fig1.png")
```

`r RefManageR::Citep(bib, "kruschke_rejecting_2018")`, Abbildung 1, S. 272


---

## Visualisierung unserer Rope-Werte, m10.6

- Ein Gro√üteil der Posteriori-Masse von `m10.6` liegt  *nicht* innerhalb des Rope. 
- Aber k√∂nnen wir umgekehrt sagen, dass ein Gro√üteil au√üerhalb liegt? Das erkennt man optischt so gut.

```{r fig.asp = .5}
plot(m10.6,plotfun = "mcmc_areas",
     regex_pars = "^cut") +
  annotate("rect",
           xmin = -100,
            xmax = 100,
            ymin = 0,
            ymax = Inf,
            fill = "red",
            alpha = .5)
```




---


## Genaue Rope-Werte


```{r echo = TRUE, results="hide"}
library(bayestestR)
rope(m10.6, range = c(-100, 100))
```

</br>


Parameter    | Anteil im ROPE  | Entscheidung 
:----------- |:--------------- |:------------- 
(Intercept)  |      0.00 %     | Nullhypothese verwerfen 
cutGood      |      8.73 %     | keine Entscheidung m√∂glich 
cutIdeal     |      1.47 %     | Nullhypothese verwerfen 
cutPremium   |     10.08 %     | keine Entscheidung m√∂glich 
cutVery Good |      6.42 %     | keine Entscheidung m√∂glich 


Im Standard werden 95%-HDI berichtet, das kann man so √§ndern, wenn man m√∂chte:

```{r echo=TRUE, eval = FALSE}
rope(m10.6, range, c(-100,100), ci = .89, ci_method = "ETI")
```

`ETI` (equal tails interval) steht f√ºr ein PI.

---

## R-Befehl zur bequemen Visualisierung von Rope

Das Paket `bayestestR` bietet eine komfortable Visualisierungsfunktion:

```{r echo = TRUE, out.width="70%"}
plot(rope(m10.6, range = c(-100, 100)))
```

---


## Beantwortung der Forschungsfrage

>    Nur das 95%-HDI f√ºr Schliffart "Ideal" schloss den Indifferenzbereich von ¬±100‚Ç¨ aus, die √ºbrigen Mittelwertsdifferenzen nicht. F√ºr die √ºbrigen Differenzen ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs m√∂glich: Es ist plauibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.

>   Die 95%HDI f√ºr die Mittelwertsdifferenzen waren wie folgt: cutGood: [-2040, 953], cutIdeal: [-2645, -4], cutPremium: [-965, 1732], cutVeryGood: [-2102, 627]. Das Modell erkl√§rte im Median ca. 3% der Varianz, also nur einen kleinen Teil.

---


