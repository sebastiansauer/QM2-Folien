
```{r}
library(gt)
library(tidyverse)
library(tidybayes)
#library(dagitty)
#library(DT)
library(rstanarm)
library(rstatix)
#library(ggdag)
#library(patchwork)
library(tidybayes)
library(modelr)
```






name: teil-2
class: middle, center



# Teil 2

## Metrische UV

---

## Geschlecht vorhersagen auf Basis der Körpergröße

[Beschreibung des Datensatzes](https://vincentarelbundock.github.io/Rdatasets/doc/openintro/speed_gender_height.html), [Datenquelle](https://vincentarelbundock.github.io/Rdatasets/csv/openintro/speed_gender_height.csv)


```{r echo = TRUE}
d <- read_csv(
"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/speed_gender_height.csv")
```


```{r fig.asp = .4}
binomial_smooth <- function(...) {
    geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)
}

d %>% 
  drop_na() %>% 
  mutate(male = ifelse(gender == "male", 1, 0),
         height_cm = height * 2.54,
         height_c = height_cm - mean(height_cm)) %>% 
  drop_na() %>% 
  mutate(male = ifelse(gender == "male", 1, 0)) %>% 
ggplot() +
  aes(x = height_c, y = male) +
  geom_jitter(alpha = .5, width = 0.1, height = 0.1) +
  binomial_smooth() +
  scale_y_continuous("Wahrscheinlichkeit für 'Mann'",
    breaks = c(0, 1))
  
```


---

## Zusammenhang von Körpergröße und 'Mann'?

>    *Forschungsfrage*: Ist der Zusammenhang von *Körpergröße* und 'Mann' positiv? Gehen also höhere Werte in Körpergröße `height` einher mit einer höheren Wahrscheinlichkeit, dass es sich um einen Mann `m` handelt?


$$
\begin{align}
m_i &\sim \mathcal{B}(1, p_i) \\
\mathcal{L}(p_i) &= \alpha + \beta \cdot \text{height}_i \\
\alpha &\sim \text{klären wir noch}  \\
\beta &\sim \text{klären wir noch}  \\
\end{align}
$$

- Die Variable $m_i$ (ob eine Person ein Mann ist) wird als binomial verteilt angenommen mit der Wahrscheinlichkeit $p_i$.
- Die Häufigkeiten, die pro Person möglich sind, begrenzen sich auf 0 und 1 (solche Ereignisse nennt man auch *Bernoulli verteilt*).
- Pro Person wird der Logit von $p_i$ modelliert als lineare Funktion der Körpergröße dieser Person.
- Entsprechend gilt auch:

$$p_i = \text{logit}^{-1}( \alpha + \beta \cdot \text{height}_i)$$








---

## Modell `m92`


```{r echo = TRUE}
d2 <- d %>% 
  drop_na() %>% 
  mutate(male = ifelse(gender == "male", 1, 0),
         height_cm = height * 2.54,
         height_c = height_cm - mean(height_cm)) 

m92 <- stan_glm(male ~ height_c, 
                family = binomial(link="logit"),
                data = d2, refresh = 0)

coef(m92)
```

- Die Modellgleichung kann man so schreiben: $Pr(y=1) = Pr(\text{male}) = \text{logit}^{-1}(`r round(coef(m92)[1], 2)` + `r round(coef(m92)[2], 2)`*\text{height})$
- Bei einer mittleren Größe (`height_c = 0`) ist der Logit für 'Mann' `r round(coef(m92)[1], 2)`. 
- WEnn dieser Wert kleiner ist als Null, ist die Wahrscheinlichkeit kleiner als 50%.
- Für jeden zusätzlichen Zentimeter Größe steigt die Wahrscheinlichkeit, dass wir 'Mann' vorhersagen um ca. `r round(coef(m92)[2], 2)` Logits.
- Der Zuwachs an Wahrscheinlichkeit ist *nicht* konstant pro zusätzlichen Logit.


---

## Umrechnen von Logits in Wahrscheinlichkeit

- Logits sind schwer zu interpretieren, rechnen wir in Wahrscheinlichkeit, $p$ um.

- Der Achsenabschnitt im zentrierten (oder z-standardisierten) Modell gibt, den Y-Wert an für eine Beobachtung mit mittleren X-Wert:

```{r echo = TRUE}
invlogit <- plogis  # Funktion, um Inv-Logit von R berechnen zu lassen

invlogit(coef(m92)[1])
```

- Bei einer Person mittleren Größe sagt unser Modell mit einer Wahrscheinlichkeit von ca. `r round(invlogit(coef(m92)[1]), 2)` vorher, dass es ein Mann ist.

```{r echo = TRUE}
invlogit(coef(m92)[1] + coef(m92)[2]*10)
```

- Bei einer Person, die 10cm größer ist als der Mittelwert, geht unser Modell von einer Wahrscheinlichkeit von `r round(invlogit(coef(m92)[1] + coef(m92)[2]*10), 2)` aus.

---


## Post befragen: 95%-PI



```{r echo = TRUE}
posterior_interval(m92, prob = .95)

invlogit(c(-1.22, -0.95))  # Von Logits in Pr umrechnen
```

Die Wahrscheinlichkeit, dass eine mittelgroße Person ein Mann ist, 
liegt zwischen ca. 23% und 28%, laut dem Modell.

Die Intervallgrenzen des Regressionsgewichts $\beta$ sind schwieriger zu interpretieren, 
da die Veränderung in den Wahrscheinlichkeiten nicht konstant sind:
Je größere eine Person, 
desto geringer der Zuwachs in Wahrscheinlichkeit (ein Mann zu sein) pro zusätzliche Logit-Einheit.




---

## Ist der Zusammenhang von Größe und 'Mann' positiv?

>    Forschungsfrage: Ist der Zusammenhang von Körpergröße und 'Mann' positiv?


Zählen wir den Anteil der Stichproben, die ein positives $\beta$ findet:

```{r echo = TRUE}
m92 %>% 
  as_tibble() %>% 
  count(height_c > 0)
```


Das hatten wir schon mit `posterior_interval()` gesehen, das ein 95%-PI ausgegeben hat, in dem die Null nicht enthalten ist.


>    Der Zusammenhang von Körpergröße und 'Mann' ist sehr sicher positiv, laut dem Modell: Je größer eine Person, desto höher die Wahrscheinlichkeit, dass sie ein Mann ist.


---

## Vorhersagen auf Basis der Post-Verteilung

>    $Pr(\text{Mann}\;|\;\text{height}_c=10, m92)?$




- Ausgabe in Logit, $\mathcal{L}$:

```{r echo = TRUE}
posterior_linpred(m92, newdata = tibble(height_c = 10)) %>%
  mean() 
```


- Ausgabe in Wahrscheinlichkeit, $Pr$:

```{r echo = TRUE, results = "hide"}
m92_post_10 <- 
  posterior_epred(m92, newdata = tibble(height_c = 10)) 

m92_post_10 %>% as_tibble() %>% 
  summarise(mean(`1`), sd(`1`))  # Punktschätzer plus Streuung
```

Vorhergesagter Wert: ca. 72% (MW, Punktschätzer) ± 2% (Streuung d.h. Standardfehler)







---

## PPV befragen 1

Betrachten wir die PPV für Personen der Größe -40, -30, ..., +40 cm größer als der Durchschnitt, hier hilft `posterior_predict()`: 

```{r echo = TRUE}
height_vec <- seq(-40, 40, by = 10)
heights_df <- tibble(height_c = height_vec)
m92_ppv <- posterior_predict(m92, newdata = heights_df) %>% 
  as_tibble()
```



Die ersten paar Zeilen von `m92_ppv`:


```{r}
m92_ppv %>%  # die ersten paar Zeilen aus der Post-Verteilung
  slice_head(n=5) %>% 
  gt() 
```


Die 9 Spalten entsprechen den 9 Werten von `height_vec`, (-40, -30, ..., +40).

---


## PPV befragen 2

>    Wie groß ist die Wahrscheinlichkeit, dass eine Person, die -40, -30, ..., 40 cm größer ist als der Durchschnitt (`group`), als Mann klassifiziert wird?




```{r echo = TRUE, results = "hide"}
m92_ppv %>%  pivot_longer(everything(), 
               names_to = "group",
               values_to = "pred") %>% 
  group_by(group) %>% 
  summarise(group_avg = mean(pred), group_sd = sd(pred))
```

.pull-left[
```{r}
m92_ppv %>% pivot_longer(everything(), 
               names_to = "group",
               values_to = "pred") %>% 
  mutate(group = as.integer(group)) %>% 
  filter(group < 6) %>% 
  group_by(group) %>% 
  summarise(group_avg = mean(pred),
            group_sd = sd(pred)) %>% 
  gt() %>% 
  fmt_number(where(is.numeric), decimals = 3)
```

]

.pull-right[
```{r results="show", fig.asp = .4}
m92_ppv %>% 
  pivot_longer(everything(), 
               names_to = "group",
               values_to = "pred") %>% 
  mutate(group = as.integer(group)) %>% 
  group_by(group) %>% 
  summarise(group_avg = mean(pred),
            group_sd = sd(pred)) %>%
  ggplot(aes(x = group)) +
  geom_errorbar(aes(ymin = group_avg - group_sd,
                    ymax = group_avg + group_sd),
                width = 0.2) +
  geom_point(aes(y = group_avg),
             alpha = .7) +
  scale_x_continuous(breaks = 1:9) +
  scale_y_continuous(breaks = c(0, .5, 1)) +
  labs(
    title = "Vorhersagen (PPV) pro Gruppe",
    caption = "Fehlerbalken zeigen MW±SD",
    y = "Wskt"
  )
```

Die Streuungswerte aus der PPV sind nur bedingt zu interpretieren.

]


---

## PPV befragen 3

>    Wie groß ist die Wahrscheinlichkeit, dass eine überdurchschnittlich große Person als Mann klassifiziert wird? Wie hoch ist die Ungewissheit dieser Klassifizierung?

- Dazu bilden wir den Mittelwert der Spalten 6-9.
- Für diesen Zweck muss die Tabelle so umgeformt werden, dass die Wahrscheinlichkeiten aller 9 Gruppen in einer Spalte stehen (`pivot_wider()`).
- Dann filtern wir die Gruppen 5-9.


```{r echo = TRUE}
m92_ppv %>% 
  pivot_longer(everything()) %>% 
  filter(name == c("6", "7", "8", "9")) %>% 
  summarise(p_mann_avg = mean(value),
            p_mann_sd = sd(value))
```




---

## Tabellen umformen von lang nach breit und zurück

- `pivot_longer()` von breit nach lang (`gather`)
- `pivot_wider()` von lang nach breit (`spread`)



```{r out.width="50%"}
knitr::include_graphics("https://github.com/gadenbuie/tidyexplain/raw/main/images/tidyr-spread-gather.gif")
```


Garrick Aden-Buie [Quelle](https://github.com/gadenbuie/tidyexplain#spread-and-gather); [vgl. auch dieses Tutorial](https://ab604.github.io/docs/coding-together-2019/data-wrangle-2.html#reshaping-data-with-pivots)


---


## Datensatz zu außerehelichen Affären


[Beschreibung des Datensatzes](https://vincentarelbundock.github.io/Rdatasets/doc/AER/Affairs.html), [Datenquelle](https://vincentarelbundock.github.io/Rdatasets/csv/AER/Affairs.csv)

```{r echo = TRUE}
d_hallodri <- read_csv(
 "https://vincentarelbundock.github.io/Rdatasets/csv/AER/Affairs.csv")
```

EDA:

.pull-left[
```{r hallodri1, echo = TRUE, results="hide"}
d_hallodri <-
  d_hallodri %>% 
  mutate(is_hallodri = 
    ifelse(affairs > 0, 1, 0),
    rating_z =
           scale(rating)) 

d_hallodri %>% 
  select(is_hallodri, rating_z) %>% 
  group_by(rating_z) %>% 
  get_summary_stats(
    type = "mean_sd")
```
]



.pull-right[
```{r fig.asp = c(0.4, 0.4)}
d_hallodri %>% 
  ggplot() +
  aes(x = rating, y = is_hallodri) +
  geom_jitter(alpha = .5) +
  scale_y_continuous(breaks = c(0, 1)) +
  stat_smooth(method = "glm", family = "binomial")

d_hallodri %>%
  mutate(rating = factor(rating),
   is_hallodri = factor(is_hallodri)) %>% 
  ggplot() +
  aes(x = rating, fill = is_hallodri) +
  geom_bar(position = "fill") 
```

]


---


## Hallodri-Modell

>  Kovariiert die Wahrscheinlichkeit $p_i$ für *Hallodri* $h_i$ (negativ) mit der (z-standardisierten) Ehezufriedenheit $r_i$?


$$
\begin{align}
h_i &\sim \mathcal{B}(1,p_i) \\
\mathcal{L}(p_i) &= \alpha + \beta \cdot r_i \\
\alpha &\sim \mathcal{N}(0, 2.5) \\
\beta &\sim \mathcal{N}(0, 2.5)
\end{align}
$$


```{r echo = TRUE}
m_hallodri1 <-
  stan_glm(is_hallodri ~ rating_z, data = d_hallodri, refresh = 0,
           family = binomial(link = "logit"))
```


💣 Der AV liegt eine metrische Variable zugrunde (`affairs`).
Zumeist ist es sinnvoller, 
die informationsreichere metrische Variable zu modellieren.
Die Dichotomisierung zu einer binären Variablen verschenkt viel Information.
Hier zu didaktischen Zwecken.

---

## Hallodri-Modell: Ergebnisse

```{r echo = TRUE}
posterior_interval(m_hallodri1, pars = "(Intercept)") %>% invlogit()
posterior_interval(m_hallodri1, pars = "rating_z")
```


- Bei mittlerer Ehezufriedenheit liegt die Wahrscheinlichkeit eines Seitensprungs bei ca. 21% bis 27% (95%-PI).
- Je höher die Ehezufriedenheit, desto geringer die Wahrscheinlichkeit für einen Seitensprung.
- Laut dem Modell ist $\beta$ mit hoher Wahrscheinlichkeit negativ.


---

## Vorhersagen bei den Hallordis

>  Wie hoch ist die Wahrscheinlichkeit für einen Seitensprung, wenn `rating_z = -3`?





.pull-left[

Punktschätzer:
```{r echo = TRUE}
predict(m_hallodri1, 
  newdata = tibble(rating_z=-3))
```


95%-PI aus der Post-Verteilung (nicht PPV) als Wahrscheinlichkeit:
```{r echo = TRUE}
posterior_epred(m_hallodri1, 
  newdata = tibble(rating_z = -3)) %>% 
  quantile(prob = c(0.025, .975))
```



]

.pull-right[

```{r echo = TRUE}
posterior_epred(m_hallodri1, 
  newdata = tibble(rating_z = -3)) %>% 
  as_tibble() %>% 
  ggplot(aes(x = `1`)) +
  geom_density()
```

]






---


## Visualisierung der Modellfunktion





```{r hallodri-plot, ech = FALSE, eval = FALSE}
d_hallodri %>%
  data_grid(rating_z = -10:2) %>% 
  add_epred_draws(m_hallodri1, ndraws = 100) %>% 
  ggplot(aes(x = rating_z, y = is_hallodri)) +
  geom_jitter(data = d_hallodri, 
              size = 1, 
              width=0.1, height = 0.1,
              alpha = .5) +
  stat_lineribbon(aes(y = .epred)) +
  scale_fill_brewer() 
```


.pull-left[

```{r ref.label = "hallodri-plot", fig.asp = 1} 

```


]


.pull-right[
- Um den charakterischen, s-förmigen Verlauf der logistischen Funktion zu zeigen, ist hier der Wertebereich des Prädiktors übermäßig nach links erweitert.

- Extreme Wahrscheinlichkeiten sind mit weniger Unsicherheit verbunden als mittlere Wahrscheinlichkeiten.

]


---


## Vorhersagen mit Ungewissheit visualisiert

.pull-left[
Vorhersagen aus der Post-Verteilung für jede Stufe von `rating_z`.

```{r fig.asp=1}
epred_ratingz <- 
  posterior_epred(m_hallodri1, 
  newdata = tibble(rating_z = -3:2)) %>% 
  as_tibble()   %>% 
  pivot_longer(everything(), 
               names_to = "rating_z",
               values_to = "is_hallodri") %>% 
  mutate(rating_z = as.integer(rating_z)) %>% 
  mutate(rating_z = rating_z - 4)



d_hallodri %>%
  data_grid(rating_z = -3:2) %>% 
  add_epred_draws(m_hallodri1, ndraws = 100) %>% 
  ggplot(aes(x = rating_z, y = is_hallodri)) +
  geom_jitter(data = d_hallodri, size = 1)  +
  stat_lineribbon(aes(y = .epred)) +
  scale_fill_brewer() +
   geom_violin(data = epred_ratingz,
                    aes(y = is_hallodri,
                  x = rating_z,
                  group = rating_z),
               size = .3,
               alpha = .5) +
  labs(title = "Violinen zeigen Post-Verteilung")
```


]

.pull-right[
Vorhersagen aus der PPV für jede Stufe von `rating_z`.

```{r fig.asp = 1}
postpred_ratingz <- 
  posterior_predict(m_hallodri1, 
  newdata = tibble(rating_z = -3:2)) %>% 
  as_tibble()   %>% 
  pivot_longer(everything(), 
               names_to = "rating_z",
               values_to = "is_hallodri") %>% 
  mutate(rating_z = as.integer(rating_z)) %>% 
  mutate(rating_z = rating_z - 4)


postpred_ratingz %>% 
  mutate(is_hallodri = as.numeric(is_hallodri)) %>% 
   count(rating_z, is_hallodri) %>% 
  mutate(is_hallodri = factor(is_hallodri)) %>% 
  ggplot(aes(x = rating_z, y = n, fill = is_hallodri)) +
  geom_col(position = "fill") +
  scale_fill_viridis_d()
```

]


---
