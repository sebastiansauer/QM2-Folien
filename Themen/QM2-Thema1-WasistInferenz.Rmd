---
title: "Thema 1: Was ist Inferenzstatistik?"
subtitle: "QM2, ROS, Kap. 1, ReThink, Kap. 1"
author: Prof. Sauer
date: WiSe 21
lang: de-DE
bibliography: /Users/sebastiansaueruser/Google Drive/Literatur/refmgt/library-ses.bib
institute: AWM, HS Ansbach
header-includes:
  - \usepackage{booktabs}
  - \usepackage{csquotes}
  - \usepackage{xspace}
  - \usepackage[ngerman]{babel}
output:
  beamer_presentation:
    toc: true
    theme: "Berkeley"
    #colortheme: "dolphin"
    # fonttheme: "structurebold"
    keep_tex: false 
    includes:
      in_header: ../libs/preamble.tex    
editor_options: 
  chunk_output_type: console
  
#numbersections: yes
csquotes: TRUE     
---


```{r global-knitr-options, include=FALSE}
knitr::opts_chunk$set(
  fig.pos = 'H',
  fig.asp = 0.618,
  fig.center = "align",
  fig.width = 5,
  out.width = "70%",
  fig.cap = "", 
  fig.path = "",
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  cache = TRUE,
  fig.show = "hold")

knitr::opts_knit$set(
  #base.dir = "img",
  root.dir = rprojroot::find_rstudio_root_file()
)

knitr::knit_hooks$set(crop = knitr::hook_pdfcrop)
```


```{r}
options("knitr.graphics.auto_pdf" = FALSE)
```


```{r echo = FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)
#library(nomnoml)
library(ggdag)
library(patchwork)
```

```{r}
source("R-Code/img.R")
```








```{r}
theme_set(theme_minimal())
```

# Was ist Inferenzstatistik?



## Deskriptiv- vs. Inferenzstatistik

\pretolerance=-1
\hyphenpenalty=0
\finalhyphendemerits=0



```{r echo = FALSE}
knitr::include_graphics("/Users/sebastiansaueruser/Google Drive/research/Publikationen/In_Arbeit/Statistik__21/images/Rahmen/desk_vs_inf-crop.pdf")
```

*Deskriptivstastistik* fasst Stichprobenmerkmale zu Kennzahlen (Statistiken) zusammen.

*Inferenzstatistik* schließt von Statistiken auf Parameter (Kennzahlen von Grundgesamtheiten).

\includegraphics[width=1em]{../img/weight.pdf} Schließen Sie die Augen und zeichnen Sie obiges Diagramm!


## Wozu ist die Inferenstatistik gut?

\begin{alertblock}{Inferenz}
Inferenz bedeutet logisches Schließen; auf Basis von vorliegenden Wissen wird neues Wissen generiert.
\end{alertblock}


\begin{alertblock}{Inferenstatistik}
Inferenzstatistik ist ein Verfahren, das mathematische Modelle (oft aus der Stochastik) verwendet, um von einer bestimmten Datenlage, die eine Stichprobe einer Grundgesamtheit darstellt, allgemeine Schlüsse zu ziehen.
\end{alertblock}


\includegraphics[width=1em]{../img/weight.pdf} Heute Nacht vor dem Schlafen wiederholen Sie die Definition. Üben Sie jetzt schon mal.

<!-- ## Die drei Aufgaben der Inferenzstatistik -->


<!-- 1. Von der Stichprobe auf die Grundgesamtheit schließen  -->

<!-- 2. Von der Experimental- auf die Kontrollgruppe zu schließen -->

<!-- 3. Vom beobachteten Messwert auf das zugrundeliegende Konstrukt zu schließen -->


## Deskriptiv- und Inferenzstatistik gehen Hand in Hand


Für jede Statistik (Kennzahl  von Stichprobendaten) kann man die Methoden der Inferenzstatistik verwenden, z.B.:



```{r echo = FALSE}
x <- tribble(
    ~Kennwert, ~Stichprobe, ~Grundgesamtheit,
  "Mittelwert", "$\\bar{X}$", "$\\mu$",
  "Streuung", "$sd$", "$\\sigma$",
  "Anteil", "$p$", "$\\pi$",
  "Korrelation", "$r$", "$\\rho$" ,
  "Regression", "$b$", "$\\beta$"
  
)

kable(x, format = "latex", escape = FALSE, booktabs = FALSE) %>%
  kable_styling(position = "center")
```


Für Statistiken (Stichprobe) verwendet man lateinische Buchstaben; für Parameter (Population) verwendet man griechische Buchstaben.

\includegraphics[width=1em]{../img/weight.pdf} Geben Sie die griechischen Buchstaben für typische Statistiken an!


## Schätzen von Parametern einer Grundgesamtheit


Meist begnügt man sich nicht mit Aussagen für eine Stichprobe, sondern will auf eine Grundgesamtheit verallgemeinern.

Leider sind die Parameter einer Grundgesamtheit zumeist unbekannt, daher muss man sich mit *Schätzungen* begnügen.

Schätzwerte werden mit einem "Dach" über dem Kennwert gekennzeichnet, z.B.


```{r echo = FALSE}
x <- tribble(
    ~Kennwert, ~Stichprobe, ~Grundgesamtheit, ~Schätzwert,
  "Mittelwert", "$\\bar{X}$", "$\\mu$", "$\\hat{\\mu}$",
  "Streuung", "$sd$", "$\\sigma$", "$\\hat{\\sigma}$",
  "Anteil", "$p$", "$\\pi$", "$\\hat{\\pi}$",
  "Korrelation", "$r$", "$\\rho$", "$\\hat{\\rho}$" ,
  "Regression", "$b$", "$\\beta$", "$\\hat{\\beta}$"
  
)

kable(x, format = "latex", escape = FALSE, booktabs = FALSE) %>%
  kable_styling(position = "center")
```



## Beispiel für eine inferenzstatistische Fragestellung



Sie testen zwei Varianten Ihres Webshops (V1 und V2), die sich im Farbschema unterscheiden und ansonsten identisch sind: Hat das Farbschema einen Einfluss auf den Umsatz?

- Dazu vergleichen Sie den mittleren Umsatz pro Tag von V1 vs. V2, $\bar{X}_{V1}$ und $\bar{X}_{V2}$.

- Die Mittelwerte unterscheiden sich etwas, $\bar{X}_{V1} > \bar{X}_{V2}$

- Sind diese Unterschiede "zufällig" oder "substanziell"? Gilt also $\mu_{V1} > \mu_{V2}$ oder gilt  $\mu_{V1} \le \mu_{V2}$?

- Wie groß ist die Wahrscheinlichkeit^[oft mit *Pr* oder *p* abgekürzt, für *probability*] $Pr(\mu_{V1} > \mu_{V2})$?


\includegraphics[width=1em]{../img/weight.pdf} *Predictive Maintenance* ist ein Anwendungsfeld inferenzstatistischer Modellierung. Lesen Sie dazu S. 3 [dieses Berichts](https://www.rolandberger.com/publications/publication_pdf/roland_berger_vdma_predictive_maintenance_d_1.pdf)!

## Was heißt "zufällig"?


\begin{alertblock}{Definition}
Unter einem zufälligen Ereignis (random) verstehen wir ein Ereignis, das nicht (komplett) vorherzusehen ist, wie etwa die Augenzahl Ihres nächsten Würfelwurfs. Zufällig bedeutet nicht (zwangsläufig), dass das Ereignisse keine Ursachen besitzt. So gehorchen die Bewegungen eines Würfels den Gesetzen der Physik, nur sind uns diese oder die genauen Randbedingungen nicht (ausreichend) bekannt.
\end{alertblock}


\includegraphics[width=1em]{../img/weight.pdf} Welche physikalischen Randbedingungen wirken wohl auf einen Münzwurf ein?


# Regression und Inferenz


## Für jede Fragestellung einen anderen Test


```{r echo = FALSE, fig.align="center", out.height="80%"}
img("entscheidungsbaum.pdf")
```


[Quelle](https://md.psych.bio.uni-goettingen.de/mv/entscheidungsbaum.pdf)


## Oder man nimmt einfach immer die Regression


```{r cheat_sheet_regr, echo = FALSE, fig.align="center", out.width="70%"}

img("linear_tests_cheat_sheet.png")

```

[Quelle](https://lindeloev.github.io/tests-as-linear/)



## Gängige statistische Tests sind Spezialfälle der Regression



```{r}
img("regression-specialcases.png")
```

- *t-Test*: Unterscheiden sich zwei Gruppen in ihren (metrischen) Mittelwerten?
- *Wilcoxon-Test*: Unterscheiden sich zwei Verteilungen?
- *Korrelastionstest*: Korrelieren zwei Merkmale?
- *Varianzanalye*: Unterscheiden sich die (metrischen) Mittelwerte in zwei oder mehr Gruppen?
- $\chi^2$-*Test*: Hängen zwei nominale Merkmale zusammen?

Diese (und mehr) Fragestellungen können mit der Regression beantwortet werden.


## To rule 'em all


```{r einring, echo = FALSE, fig.align="center", out.width="50%"}

img("einring.jpg")

```




[Quelle](https://imgflip.com/i/5m9qrp)


## Was war noch mal die Regression?

- Mit der Regression kann man Zielvariablen in Abhängigkeit von Prädiktorvariablen vorherzusagen. 

- Dabei erlaubt die Regression die Quantifizierung der Ungewissheit der Vorhersagen.


```{r plot-regr-uncertainty, echo = FALSE,  out.width=c("40%", "40%")}

img("fig1-1a.png")
img("fig1-1b.png")
```

[Quelle](https://avehtari.github.io/ROS-Examples/ElectionsEconomy/hibbs.html)


\includegraphics[width=1em]{../img/weight.pdf} Erläutern Sie die Grundidee der Regression!

## Beispiele zur Quantifizierung von Ungewissheit


\pretolerance=-1
\hyphenpenalty=0
\finalhyphendemerits=0



- Morgen regnet's $\Leftrightarrow$ Morgen wird es hier mehr als 0 mm Niederschlag geben ($p=97\%$).

- Methode $A$ ist besser als Methode $B$ $\Leftrightarrow$ Mit einer Wahrscheinlichkeit von 57% ist der Mittelwert für Methode $A$ höher als für Methode $B$.

- Die Maschine fällt demnächst aus $\Leftrightarrow$ Mit einer Wahrscheinlichkeit von 97% wird die Maschine in den nächsten 1-3 Tagen ausfallen, laut unserem Modell.

- Die Investition lohnt sich $\Leftrightarrow$ Die Invesition hat einen Erwartungswert von 42 Euro; mit 90% Wahrscheinlichkeit wird der  Gewinn zwischen -10000 und 100 Euro.



\includegraphics[width=1em]{../img/weight.pdf} Geben Sie weitere Beispiele an!






## Die Regressionsgleichung

In voller Pracht:


$$y = \beta_0 + \beta_1x + \epsilon$$



- $y$: Zielvariable^[Abhängige Variabe, Kriterium] (vorherzusagen)
- $\beta_0$: Achsenabschnitt
- $\beta_1$: Regressionsgewicht (Steigung der Regressionsgeraden)
- $\epsilon$: "Fehler"; Ungenauigkeit des Modells, oft mit $\sigma$ quantifiziert


\includegraphics[width=1em]{../img/weight.pdf} Geben Sie ein Beispiel an, das die Teile der Regressionsgleichung aufgreift.

## Datenbeispiel


```{r echo = TRUE, results = "hide"}
data(mtcars)
library(rstanarm)
lm1 <- stan_glm(mpg ~ hp, data = mtcars)
```


```{r echo = TRUE, results = "hide"}
print(lm1)
```

```
            Median MAD_SD
(Intercept) 30.0    1.7  
hp          -0.1    0.0  

Auxiliary parameter(s):
      Median MAD_SD
sigma 3.9    0.5   
```



## Visualisierung zum Datenbeispiel


```{r}
lm1_glm <- lm(mpg ~ hp, data = mtcars)

mtcars <- 
  mtcars %>% 
  mutate(pred = 30 - hp*0.07)


pred_interval <-
  tibble(
    hp = seq(min(mtcars$hp), max(mtcars$hp), by = 1),
    mpg = predict(lm1_glm, newdata = data.frame(hp)),
    lwr = mpg - 2*3,
    upr = mpg + 2*3
  )

```


```{r plot1, fig.asp=0.5}
plot1 <- 
  ggplot(mtcars,
       aes(x = hp, y = mpg)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  annotate("point", x = 200, 
           y = predict(lm1_glm, newdata = data.frame(hp = 200)),
           color = "red",
           alpha = .5,
           size = 5)
plot1

```




Rot markiert: Die Punktschätzugn von `mpg` für `hp=200`.

\includegraphics[width=1em]{../img/weight.pdf} Geben Sie ein vergleichbares Beispiel an!


## Der Punktschätzer berücksichtigt nicht die Ungewissheit des Models

Mindestens zwei Arten von Ungewissheit müssen wir in unseren Vorhersagen berücksichtigen:

- zur Lage der Regressionsgeraden ($\beta_0$, $\beta_1$)
- zu Einflüssen, die unser Modell nicht kennt ($\epsilon, \sigma$)

:::::: {.columns}
::: {.column width="50%"}
### Ungewissheit in $\beta_0, \beta1$
```{r plt-uncert-beta0beta1}
plot2 <- 
  ggplot(mtcars,
       aes(x = hp, y = mpg)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) +
  annotate("point", x = 200, 
           y = predict(lm1_glm, newdata = data.frame(hp = 200)),
           color = "red",
           alpha = .5,
           size = 5)
plot2
```

::: 
::: {.column width="50%"}
### Ungewissheit durch $\epsilon$ ($\sigma$)

```{r plot-uncertainty-eps}
ggplot(mtcars) +
  aes(x = hp, y = mpg) +
  geom_point()+
  geom_ribbon(data = pred_interval,
              aes(ymin = lwr, ymax = upr,
                  y = mpg,
                  x = hp),
              fill = "blue",
              alpha = .1) + 
  geom_smooth(method = "lm", se = FALSE) +
  annotate("point", x = 200, 
           y = predict(lm1_glm, newdata = data.frame(hp = 200)),
           color = "red",
           alpha = .5,
           size = 5)


```


:::
::::::



## Vorhersage-Intervall: berücksichtigt Ungewissheit in $\beta_0, \beta_1, \epsilon$

Das Vorhersage-Intervall berücksichtigt Ungewissheit in $\beta_0, \beta_1, \epsilon$ bei der Vorhersage von $\hat{y_i}$.


```{r plot-pred-interval}
pred_interval2 <-
  predict(lm1_glm, 
          newdata = data.frame(hp = pred_interval$hp), 
          interval = "prediction") %>% 
  as_tibble() %>% 
  rename(mpg = fit) %>% 
  mutate(hp = pred_interval$hp)



ggplot(mtcars) +
  aes(x = hp, y = mpg) +
  geom_point()+
  geom_ribbon(data = pred_interval2,
              aes(ymin = lwr, ymax = upr,
                  y = mpg,
                  x = hp),
              fill = "blue",
              alpha = .1) + 
  geom_smooth(method = "lm", se = FALSE) +
  annotate("point", x = 200, 
           y = predict(lm1_glm, newdata = data.frame(hp = 200)),
           color = "red",
           alpha = .5,
           size = 5)
```


\includegraphics[width=1em]{../img/weight.pdf} Interpretieren Sie den Ungewissheitskorridor!

## Wozu man die Regression benutzt

\pretolerance=-1
\hyphenpenalty=0
\finalhyphendemerits=0



- *Vorhersagen* (Wie stehen die Aktien morgen? Wann wird die Maschine ausfallen?)

- *Zusammenhänge untersuchen* (Wie stark ist der Zusammenhang, der 'statistische Effekt' von Lernzeit und Klausurerfolg?)

- *Adjustieren* (Was ist der Einfluss von Lernzeit von Klausurerfolg, wenn man die Motivation konstant hält?)

- *Kausalinferenz* (Wie groß ist der kausale Einfluss von Lernzeit auf den Klausurerfolg?)


\includegraphics[width=1em]{../img/weight.pdf} Geben Sie weitere Beispiele an!


## In Experimenten kann man die Ergebnisse kausal interpretieren



```{r echo = FALSE,  out.width=c("40%", "40%")}
include_graphics("/Users/sebastiansaueruser/github-repos/ROS-Examples/SimpleCausal/figs/overview_1a.pdf")
include_graphics("/Users/sebastiansaueruser/github-repos/ROS-Examples/SimpleCausal/figs/overview_1b.pdf")
```


In einem gut gemachten Experiment geben die Koeffizienten der Regression den kausalen Effekt wider.


\includegraphics[width=1em]{../img/weight.pdf} Begründen Sie obige Aussage!


## Kausalmodell eines einfachen Experiments



```{r dag1}
dagify(y ~ x,
       y ~ z,
       labels = c(x = "Impfung",
                  y = "Symptome",
                  z = "Sonstige")) %>% 
  ggdag(use_labels = "label") +
  theme_dag()
```

Statistiken in (gut gemachten) Experimenten können kausal interpretiert werden: Der statistische Zusammenhang von *Impfung* auf *Symptome* entspricht dem kausalen Effekt.


## Beobachtungsstudien können nicht ohne Weiteres kausal interpretiert werden

[Männer aufgepasst: Glatze macht Corona?!](https://www.webmd.com/lung/news/20200615/male-baldness-may-increase-severe-covid-19-risk)


```{r dag2, out.width="50%"}
dagify(y ~ z,
       x ~ z,
       labels = c(x = "Glatze",
                  y = "Corona-Symptome",
                  z = "Alter")) %>% 
  ggdag_dseparated(from = "x",
                   to = "y",
                   use_labels = "label") +
  theme_dag()
```



Laut diesem Modell gibt es keinen kausalen Zusammenhang von *Glatze* zu *Corona*. Der statistische Zusammenhang ist ein *Scheinzusammenhang* (nichtkausal).


\includegraphics[width=1em]{../img/weight.pdf} Finden Sie ein weiteres Beispiel für einen Scheinzusammenhang!

## Die lineare Regression ist erstaunlich flexibel

Z.B. 

- *Nichtlineare* Zusammenhänge

- Interaktionen

```{r echo = FALSE,  out.width=c("40%", "40%")}
include_graphics("/Users/sebastiansaueruser/github-repos/ROS-Examples/SimpleCausal/figs/overview_2a.pdf")
include_graphics("/Users/sebastiansaueruser/github-repos/ROS-Examples/Interactions/figs/interactions_male.pdf")
```

\includegraphics[width=1em]{../img/weight.pdf} Nennen Sie je ein Beispiel!

## Beispiel für nichtlineare Modelle: Die Log-Y-Regression

Die Log-Y-Regression ist geeignet, um exponenzielles Wachstum darzustellen.

$$log(y) = \tilde{x}$$

mit $\tilde{x} = \beta_0 + \beta_1 \cdot x$

Exponentiert man beide Seite, so erhält man:

$$y = e^{\tilde{x}}=e^{\beta_0 + \beta_1 \cdot x}$$

$e$ ist die Eulersche Zahl: 2.71...


## Beispiele für exponentielle Zusammenhänge



\pretolerance=-1
\hyphenpenalty=0
\finalhyphendemerits=0




- Eine Bakterienmenge verdoppelt sich jeden Tag
- Pro Jahr erzielt eine Kapitalanlage 10% Zinsen
- Während einer bestimmten Periode verdoppelten sich die Coronafälle alle 10 Tage
- Die Menge der Vitamine in einem Lebensmittel verringert sich pro Zeiteinheit um den Faktor $k$


Generell bieten sich es an, zur Modellierung von Wachstumsprozessen auf exponenzielles Zusammenhänge - und damit auf Log-Y-Regression - zurückzugreifen.


## So sieht exponenzielles Wachstum aus


```{r echo = FALSE}
euler_e <- 2.71
d2 <- 
  tibble(
    x = rep(0:100, 10),
    y_hat = euler_e^(0.1*x) %>% round(2),
    e = rnorm(n = (101)*10) %>% round(2),
    y = y_hat + e
  )
```

```{r fig.asp = .5}
ggplot(d2) +
  aes(x = x, y = y) +
  geom_point() +
  geom_smooth()
```



- Steigt $X$ um 1 Einheit, so steigt $Y$ um einen konstanten Faktor: exponentielles Wachstum.

- Beispiel: Verdopplung: $1,2,4,...$, nach 10 Schritten: $2^{10}=1024$, nach 20 Schritten: $2^{20} \approx 10^6$. 

- Exponenzielles Wachstum wächst am Anfang (scheinbar) langsam, später sehr schnell. Die Geschwindigkeit wird leicht unterschätzt.




## Häufig sind Gruppen nicht direkt vergleichbar


- *Beispiel*: Die Heilungsraten in der Experimentalgruppe waren höher als in der Kontrollgruppe. Allerdings waren die Personen der Experimentalgrupe auch gesünder (als die Personen der Kontrollgruppe). Um den Kausaleffekt der Behandlung zu schätzen, müssen solche vorab bestehenden Unterschiede zwischen den Gruppen berücksichtigt (adjustiert) werden; mit der Regression ist dies möglich.


```{r out.width = "40%"}
include_graphics("/Users/sebastiansaueruser/github-repos/ROS-Examples/SimpleCausal/figs/overview_3.pdf")
```


## Keine vorschnelle Kausalinterpretation


- Kausalinterpretationen statistischer Ergebnisse (z.B. Mittelwertsdifferenz von Behandlungs- vs. Kontrollgruppe) ist nur möglich, wenn
    - die Studie gut kontrolliert und randomisiert ist (und die Stichprobe groß ist) oder
    - bestehende Unterschiede nicht randomisiert, aber  kontrolliert wurden oder
    -  diese gemessen und in der Regressionsanalyse berücksichtigt wurden
    
    
Ansonsten muss auf eine Kausalinterpretation verzichtet werden.

Allerdings ist es möglich, Art und Stärke von Zusammenhängen zu schätzen.





## Was ist ein (statistisches) Modell?

- Ein Modell ist ein vereinfachtes Abbild der Wirklichkeit, z.B. in Form einer Landkarte, eines Modellauto oder einer Gleichung [@sauer_moderne_2019].

- Greift relevante Aspekte der Wirklichkeit heraus (und vernachlässigt andere).

- Die Regression eignet sich gut zum Modellieren von statistischen Sachverhalten.


```{r, echo = FALSE} 
img("Modell-crop.pdf")
```



## Beispiel für ein statistisches Modell


$$E = \beta_0 + \beta_1\cdot L + \epsilon,$$

wobei $E$ für *Erfolg in der Klausur* steht, $L$ für die *Lernzeit* und $\epsilon$ für den "Fehler" des Modells, sprich sonstige Einflussgrößen, die im Modell nicht berücksichtigt werden.


## Vorsicht bei Extrapolation von Trends

```{r}
img("extrapolating.png")
```

[Quelle](https://imgs.xkcd.com/comics/extrapolating.png)

## Der Golem von Prag


:::::: {.columns}
::: {.column width="50%"}
```{r, echo = FALSE, out.width="50%"} 
img("170px-Golem_and_Loew.jpg")
```
[Quelle](https://de.wikipedia.org/wiki/Golem)

::: 
::: {.column width="50%"}


Der Golem von Prag, eine vom Menschen geschaffene Kreatur gewaltiger Kraft, die Befehle wörtlich ausführt. 

Bei kluger Führung kann ein Golem Nützliches vollbringen.

Bei unüberlegter Verwendung wird er jedoch großen Schaden anrichten.
:::
::::::


## Wissenschaftliche Modelle sind wie Golems

:::::: {.columns}
::: {.column width="50%"}
### Golem
- Besteht aus Lehm
- Belebt durch "Wahrheit"
- Mächtig
- dumm
- Führt Befehle wörtlich aus
- Missbrauch leicht möglich
- Märchen
::: 
::: {.column width="50%"}
### Modell
- Besteht aus ~~Lehm~~Silikon
- Belebt durch Wahrheit (?)
- Manchmal mächtig
- simpler als die Realität
- Führt Befehle wörtlich aus
- Missbrauch leicht möglich
- Nicht einmal falsch
:::
::::::

*Wir bauen Golems.*









# Klassische vs. Bayes-Inferenz


## Klassische Inferenz: Frequentismus


- Die Berücksichtigung von Vorwissen zum Sachgegenstand wird vom Frequentismus als subjektiv zurückgewiesen.
- Nur die Daten selber fliesen in die Ergebnisse ein
- Wahrscheinlichkeit wird über relative Häufigkeiten definiert.
- Es ist nicht möglich, die Wahrscheinlichkeit einer Hypothese anzugeben. 
- Stattdessen wird angegeben, wie häufig eine vergleichbare Datenlage zu erwarten ist, wenn die Hypothese gilt und der Versuch sehr häufig wiederholt ist.
- Ein Großteil der Forschung (in den Sozialwissenschaften) verwendet diesen Ansatz.


## Bayesianische Inferenz

- Vorwissen (Priori-Wissen) fließt explizit in die Analyse ein (zusammen mit den Daten).
- *Wenn* das Vorwissen gut ist, wird die Vorhersage genauer, ansonsten ungenauer.
- Die Wahl des Vorwissens muss explizit (kritisierbar) sein.
- In der Bayes-Inferenz sind Wahrscheinlichkeitsaussagen für Hypothesen möglich.
- Die Bayes-Inferenz erfordert mitunter viel Rechenzeit und ist daher erst in den letzten Jahren (für gängige Computer) komfortabel geworden.


## Vergleich von Wahrscheinlichkeitsaussagen

\pretolerance=-1
\hyphenpenalty=0
\finalhyphendemerits=0


::: columns

:::: column
### Frequentismus

- zentrale Statistik: *p-Wert*

- "Wie wahrscheinlich ist der Wert der Teststatistik (oder noch extremere Werte), vorausgesetzt die Nullhypothese gilt und man wiederholt den Versuch unendlich oft (mit gleichen Bedingungen aber zufällig verschieden)?"

::::

:::: column
### Bayes-Statistik

- zentrale Statistik: *Posteriori-Verteilung*

- "Wie wahrscheinlich ist die Forschungshypothese, jetzt nachdem wir die Daten kennen laut unserem Modell?"
::::

:::

\includegraphics[width=1em]{../img/weight.pdf} Recherchieren Sie eine Definition des p-Werts und lesen Sie sie genau.

## Frequentist und Bayesianer


```{r out.width="40%"}
img("frequentists-vs-bayesians-2x.png")
```


[Quelle](https://xkcd.com/1132/)


## Beispiel zum Nutzen von Apriori-Wissen 1


\pretolerance=-1
\hyphenpenalty=0
\finalhyphendemerits=0


- Ein Betrunkener behauptet, er könne hellsehen.

- Er wirft eine Münze 10 Mal und sagt jedes Mal korrekt vorher, welche Seite oben landen wird.

- Die Wahrscheinlichkeit dieses Ergebnisses ist sehr gering ($2^{-10}$) unter der Hypothese, dass die Münze fair ist, dass Ergebnis also "zufällig" ist.

- Unser Vorwissen lässt uns allerdings trotzdem an der Hellsichtigkeit des Betrunkenen zweifeln, so dass die meisten von uns  die Hypothese von der Zufälligkeit des Ergebnisses wohl nicht verwerfen.



## Beispiel zum Nutzen von Apriori-Wissen 2


\pretolerance=-1
\hyphenpenalty=0
\finalhyphendemerits=0




- Eine Studie fand einen "großen Effekt" auf das Einkommen von Babies, eine Stunde pro Woche während zwei Jahren an einem psychosozialen Entwicklungsprogramm teilnahmen (im Vergleich zu einer Kontrollgruppe), $n=127$.

- Nach 20 Jahren war das mittlere Einkommen der Experimentalgruppe um 42% höher (als in der Kontrollgruppe) mit einem Konfidenzintervall von 
[+2%,+98%].

- Allerdings lässt uns unser Vorwissen vermuten, dass so ein Treatment das Einkommen nach 20 Jahren kaum verdoppeln lässt. Wir würden den Effekt lieber in einem konservativeren Intervall schätzen (enger um Null).


## Regression in R, der schnelle Weg zum Glück


*Bayesianische* Inferenz in der Regression^[Vergessen Sie nicht, das Paket `rstanarm` zu installieren]:

```{r eval = FALSE, echo = TRUE}
library(rstanarm)
lm1 <- stan_glm(y ~ x, data = meine_daten)
```


*Klassische* Inferenz in der Regression:


```{r eval = FALSE, echo = TRUE}
lm1 <- lm(y ~ x, data = meine_daten)
```


\includegraphics[width=1em]{../img/weight.pdf} Führen Sie den Code an echten Daten aus!




<!-- # Wachstum -->

<!-- ## Seerose -->

<!-- - Eine Seerose wächst auf einem Teich. [Schön.](https://www.flickr.com/photos/182338742@N07/49286585198/in/faves-193287163@N02/) -->
<!-- - Tag 1: 1 Seerose. Tag 2: 2 Seerosen. Tag 3: 4 Seerosen, etc. -->
<!-- - Am Tag 100 ist der See komplett mit Seerosen bedeckt. -->

<!-- **An welchem Tag ist der See zu 50% mit Seerosen bedeckt?** -->


<!-- ## Wachstumsschritte der Seerose -->


<!-- $$\text{Menge} = 2^{\text{Tage}}$$ -->

<!-- :::::: {.columns} -->
<!-- ::: {.column width="50%"} -->

<!-- ```{r tab11noeval, results = "hide", eval = TRUE, echo = TRUE} -->
<!-- d <- tibble( -->
<!--   Tag = 0:10, -->
<!--   Menge = 2^Tag)  -->
<!-- ``` -->
<!-- :::  -->
<!-- ::: {.column width="50%"} -->
<!-- ```{r tab11, results = "asis"} -->
<!-- tab11 <- -->
<!--   tibble(Tag = 0:10, -->
<!--          Menge = 2^Tag) %>%  -->
<!--   kable() -->

<!-- print(tab11) -->
<!-- ``` -->
<!-- ::: -->
<!-- :::::: -->






<!-- ## Der Logarithmus gibt die Anzahl der (Wachstums-)Tage -->


<!-- ```{r echo = TRUE, size = "tiny"} -->
<!-- log(d$Menge, base = 2) -->
<!-- ``` -->


<!-- *Logarithmieren* liefert von einer Zahl (hier `Menge`) den Exponenten zu einer Basis (hier `2`) zurück. -->

<!-- Umgekehrt liefert *Potenzieren* zu einer Basis (hier `2`) die `Menge` zurück. -->

<!-- ```{r echo = TRUE, size = "tiny"} -->
<!-- 2^d$Tag -->
<!-- ``` -->


<!-- Wachstumsprozesse sind oft multiplikativ, z.B. eine Seerose, die sich in einem Zeitabschnitt $t$ verdoppelt. -->

<!-- ## Rechenregeln für Potenzen -->


<!-- - $a^n = a \cdot a \cdot a \ldots a$ ($n$ Faktoren, $n \in \mathbb{N}$) -->
<!-- - $a^1 = a$ -->
<!-- - $a^0 = 1$ -->
<!-- - $a^{-n} = \frac{1}{a^n}$ -->
<!-- - $a^{\frac{1}{n}} = \sqrt[n]{a}$ -->
<!-- - $a^n \cdot a^m = a^{n+m}$ -->
<!-- - $\frac{a^n}{a^m} = a^{n-m}$ -->
<!-- - $a^n \cdot a^m = (a\cdot b)^n$ -->
<!-- - $\frac{a^n}{b^n} = \left(\frac{a}{b}\right)^n$ -->
<!-- - $(a^n)^m = a^{(n\cdot m)}$ -->


<!-- ## Logarithmus -->

<!-- Die Zahl $x \in \mathbb{R}$ mit $b^x=a$ heißt Logarithmus von $a$ zur Basis $b$. Sie wird mit $x = log_b(a)$ bezeichnet [@cramer_vorkurs_2015]. Dabei seien $a,b > 0$ mit $b \ne1$. -->


<!-- ```{r echo = TRUE} -->
<!-- log(c(2, 4, 8), base = 2) -->
<!-- log(c(10, 100, 1000), base = 10) -->
<!-- log(c(2.71, 2.71^2)) %>% round() -->
<!-- ``` -->


<!-- Gängige Basen sind 2, 10 und $e$ (Eulersche Zahl: $2.7178...$). -->




<!-- ## Rechenregeln zum Logarithmus -->

<!-- - $\text{log}_b(1)=0$ -->
<!-- - $\text{log}_b(b)=1$ -->
<!-- - $b^{\text{log}_b(a)}=a$ -->
<!-- - $\text{log}_b(b^a)=a$ -->

<!-- - $\text{log}_c(a\cdot b) = \text{log}_c(a) + \text{log}_c(b)$ -->
<!-- - $\text{log}_c(\frac{a}{b}) = \text{log}_c(a) - \text{log}_c(b)$ -->
<!-- - $\text{log}_c(b^a) = a \cdot \text{log}_c(b)$ -->




# Ungewissheit quantifizieren

## Was ist Wahrscheinlichkeit?

\pretolerance=-1
\hyphenpenalty=0
\finalhyphendemerits=0



Die Wahrscheinlichkeit $p$ quantifiziert *Ungewissheit* im Hinblick auf eine Aussage bzw. ein Ereignis $A$, gegeben eines Hintergrundwissen $H$. $p=0$ heißt, wir halten die Aussage (das Ereignis) für falsch (unmöglich); $p=1$ heißt, wir halten die Aussage (das Ereignis) für wahr (sicher). $0<p<1$ heißt, wir sind (mehr oder weniger) unsicher bzgl. der Aussage bzw. ob das Ereignis zutrifft.

- $p(\text{Kopf werfen mit einer fairen Münze}) = 1/2$.

- $p(\text{eine 6 würfeln mit einer fairen Würfel}) = 1/6$.

- $p(\text{Entweder ist heute Montag oder nicht}) = 1$.

- $p(\text{Berlin ist die Hauptstadt von Frankreich}) = 0$.


\includegraphics[width=1em]{../img/weight.pdf} Weitere Beispiele?

## Zufallsexperiment

\pretolerance=-1
\hyphenpenalty=0
\finalhyphendemerits=0


- Als Zufallsexperiment bezeichnen wir einen Vorgang, bei dem wir wissen, was alles passieren könnte, aber nicht sicher sind, was genau passiert.

- Die Menge der möglichen Ergebnisse nennt man *Grundraum* (*Ergebnisraum*) $\Omega$. Beim Würfelwurf: $\Omega = \{1, 2, 3, 4, 5, 6\}$

- Jede Teilmenge $A \subseteq \Omega$ nennt man ein *Ereignis*. Beim Würfelwurf: z.B. $A = \{2, 4, 6\}$, eine gerade Zahl werfen.

- Ein Ereignis, das genau *ein* Element enthält, heißt *Elementarereignis.*

- Ein Ereignis, das alle Elementarereignisse aus $\Omega$ enthält, die nicht zum Ereignis $A$ gehören, nennt man das Komplementärereignis (Komplement) $A^C$ (auch: $\overline{A}, \neg A$). Beim Würfelwurf: Das Komplement von $A=\{2,4,6\}$ ist $A^C=\{1,3,5\}$, die ungeraden Zahlen.

\includegraphics[width=1em]{../img/weight.pdf} Beschreiben Sie ein weiteres Zufallsexperiment!


## Additionsregel


Die Wahrscheinlichkeit, dass mindestens eines der beiden sich ausschließenden Ereignissen $A$ und $B$ der Fall ist, ist durch die Additionsregel gegeben:

$Pr(\text{A oder B}) = Pr(A \cup B) = Pr(A) + Pr(B)$

Beispiel: Wahrscheinlichkeit mit einem "fairen" Würfelwurf $X$ eine 1 oder 2 zu werfen:

$Pr(X=1 \cup X=2) = Pr(X=1) + Pr(X=2) = 1/6 + 1/6 = 1/3$


\includegraphics[width=1em]{../img/weight.pdf} Was ist $Pr(X < 4)$, $Pr(1 \le X \le 6)$?

## Unabhängigkeit zweier Ereignisse

Zwei Ereignisse sind *(stochastisch) unabhängig*, wenn Kenntnis des einen uns keine Information gibt, ob das andere der Fall ist. Ansonsten nennt man die beiden Ereignisse (stochastisch) *abhängig* oder *zusammenhängend.*

Angenommen wir werfen zwei faire Münzen. Wir wissen, die erste Münze zeigt *Kopf*. Dieses Wissen gibt uns keine weitere Information, welche Seite bei der zweiten Münze oben liegt.

Auf der anderen Seite sind Aktienkurs häufig voneinander abhängig. Weiß man, dass eine Aktie gestiegen ist, so ist es (häufig) wahrscheinlich, dass die andere auch gestiegen ist.

*Achtung:* Stochastische (Un)abhängigkeit impliziert nicht kausale (Un)abhängigkeit.


## Beispiele für abhängige und unabhängige Ereignisse $A$ und $B$

:::::: {.columns}
::: {.column width="50%"}
*Unabhängig*

- Münzwurf 1 (A) und Münzwurf 2 (B), jeweils fair
- Meine Stimmung (A) und ob das heutige Datum eine Primzahl ist (B)
- Zwei Passanten getrennt zu ihrer Meinung zu einem politischen Thema befragen
- Die Körpergröße zweier zufällig gezogener Personen (A und B) 
::: 
::: {.column width="50%"}
*Abhängig*

- Körpergröße zweier Geschwister (A und B)
- Lernleistung zwier Schüleris A und B der gleichen Klasse
- PS-Zahl (A) und Spritverbrauch (B)
- Augenzahl beim zweimaligen Wurf (A und B) eines gezinkten Würfels
- Geschlecht (A) und ob die Person Papst ist (B)
:::
::::::




## Multiplikationsregel für unabhängige Ereignisse

Seien $A$ und $B$ zwei unabhängige Ereignisse, dann nennt man die *gemeinsame Wahrscheinlichkeit* $Pr(AB)$, die Wahrscheinlichkeit, dass beide Ereignisse eintreten. Sie berechnet sich als Produkt der jeweiligen Wahrscheinlichkeiten von $A$ und $B$:

$$Pr(A \text{ und } B ) = Pr(AB) = Pr(A \cap B) = Pr(A) \cdot Pr(B)$$

Wirft man zwei faire Münzen^[Im Folgenden immer als fair angenommen], so ist die Wahrscheinlichkeit, dass beide Kopf zeigen: $Pr(KK) = Pr(K) \cdot Pr(K) = 1/2 \cdot 1/2 = 1/4$.


\includegraphics[width=1em]{../img/weight.pdf} Was ist $Pr(ZZ)$? Ist $Pr(ZK) = Pr(KZ)$?


## Beispiele für die Multiplikationsregel unabhängiger Ereignisse

- Zwei Mal hintereinander eine 6 werfen (fairer Würfel): $Pr(6, 6) = Pr(6) \cdot Pr(6) = 1/6 \cdot 1/6 = 1/36$.

- Beim Lotto wird erst die Zahl $42$ und dann die Zahl $1$ gezogen: $Pr(42,1)=1/49 \cdot 1/48 \approx  `r round(1/49*1/48, 5)`$.

- Bei der Klausur alle 10 Richtig-Falsch-Fragen *r*ichtig zu raten: $Pr(10r) = 1/2^{10} \approx  `r round(0.5^10, 3)`\approx 1/1000$ .

- Wenn man in der Disko 10 Personen anspricht, Korb-Wahrscheinlichkeit $p(K)=9/10$ beträgt, wie hoch ist die Wahrscheinlichkeit    nicht alleine nach hause zugehen? $Pr(\neg0) = 1-0.9^{10} \approx  `r round(1-0.9^10, 5)`$.

- Ei Forscheri führt 10 statistische Tests durch, jeweils mit 10% Gefahr, dass ein falsch-positives Ergebnis zustande kommt. Wie hoch ist die Wahrscheinlichkeit für mindestens 1 falsch-positives Ergebnis? $Pr(\neg 0 FP) = 1 - 0.9^{10} \approx `r round(1 - 0.9^10, 2)`$







## Münzen werfen als Baum: Anzahl *Kopf* nach 2 Würfen



:::::: {.columns}
::: {.column width="50%"}


```{r, out.width="100%", echo = FALSE}
img("muenz1.png")

```

::: 
::: {.column width="50%"}
```{r}
tibble::tribble(
  ~Ereignis,               ~Pr,
       "0K", "1/2 * 1/2 = 1/4",
       "1K", "1/4 + 1/4 = 1/2",
       "2K", "1/2 * 1/2 = 1/4"
  ) %>% 
  kbl()
  
```


:::
::::::


\includegraphics[width=1em]{../img/weight.pdf} Zeichnen Sie den Baum und berechnen Sie die Wahrscheinlichkeiten für eine gezinkte Münze mit $P(K) = 2/3$.

## Münzen werfen als Baum: Anzahl *Kopf* nach 3 Würfen





```{r, out.width="70%", echo = FALSE}
img("muenz2.png")

```

```{r}
tibble::tribble(
  ~Ereignis,                     ~Pr,
       "0K", "1/2 * 1/2 * 1/2 = 1/8",
       "1K", "1/8 + 1/8 + 1/8 = 3/8",
       "2K",          "3 * 1/8 = 3/8",
       "3K", "1/2 * 1/2 * 1/2 = 1/8"
  ) %>% 
  kbl()
  
```




## Wahrscheinlichkeit ist abhängig vom Hintergrundwissen ($H$)


 $Pr(A|H)$: Die Wahrscheinlichkeit von $A$, *gegeben* $H$. 
 
 - A: "Sokrates ist sterblich."; H: "Alle Menschen sind sterblich und Sokrates ist ein Mensch." $\implies Pr(A|H) = 1$.

- A: "Die Münze zeigt Kopf"; H: "Wir haben keinen Grund anzunehmen, dass eine der beiden Seiten häufiger oben liegt oder das sonst etwas passiert." $\implies Pr(A|H)=1/2$.

- A: "Schorsch, das rosa Einhort, mag Bier."; H: "50% der rosa Einhörner mögen Bier." $\implies Pr(A|H) = 1/2$.

- Die Wahrscheinlichkeit eine 6 zu würfeln (A), gegeben dem Hintergrundwissen (H), dass der Würfel "fair" ist, d.h. wir kein Wissen haben, dass eine Augenzahl häufiger auftritt, ist $1/6$.






## Hintergrundwissen ist subjektiv


Ich habe gerade einen Stift in meiner Hosentasche (links oder rechts). Wie groß ist die Wahrscheinlichkeit, dass der Stift in meiner linken Tasche ist (und nicht in der rechten)?

Bezogen auf *Ihr* Hintergrundwissen gilt: $Pr(\text{A="Stift links"|H="kein besonderes Wissen zu der Frage"}) = 1/2$.

Bezogen auf *mein* Hintergrundwissen gilt: $Pr(\text{A="Stift links"|H="Der Stift ist links"}) = 1$.

@briggs_uncertainty_2016


\includegraphics[width=1em]{../img/weight.pdf} Geben Sie ein weiteres Beispiel für die Subjektivität von Hintergrundwissen an! Formalisieren Sie es wie oben gezeigt.

## Bedingte Wahrscheinlichkeit

Wie groß ist die Wahrscheinlichkeit:

- die Klausur zu bestehen, *wenn* man gelernt hat?
- von schlechter Laune, *gegeben* es ist Montag?
- schwer an Corona zu erkranken, *unter der Bedingung*, man ist geimpft? 

$Pr(A|H)$ ist die Wahrscheinlichkeit, dass $A$ eintritt, *gegeben* bzw. *unter der Bedingung*, dass $H$ eingetreten ist.


Formel der bedingten Wahrscheinlichkeit:

$$Pr(B|l) = \frac{Pr(B \cap l)}{Pr(l)}$$

## Kontingenztabelle zur Berechnung von Wahrscheinlichkeiten


Beispiel aus den Klausurergebnissen bei Prof. Süß:

```{r}
tibble::tribble(
               ~., ~"bestanden (B)", ~"nicht (¬B)", ~SUMME,
   "hat gelernt (l)",        36L,             6L,    42L,
  "nicht (¬l)",        12L,            24L,    36L,
          "SUMME",        48L,            30L,    78L
  ) %>%  
  kbl()

```

\vspace{1cm}


Randwahrscheinlichkeit: $Pr(B) = 48/78 \approx 0.61 \quad Pr(l) = 42/78 \approx 0.54$

Bedingte Wahrscheinlichkeit: $Pr(B|l) = 36/42 \approx \frac{0.46}{0.54} \approx 0.86 \quad Pr(l|B) = 42/48 \approx 0.88$




Gemeinsame Wahrscheinlichkeit: $Pr(B \cap l) = Pr(l \cap B) = Pr(Bl) = Pr(lB) = 36/78 \approx 0.46$





## Visualierung von gemeinsamer und bedingter Wahrscheinlichkeit


```{r out.width="70%", eval = TRUE, fig.width=7}
source("R-Code/img16.R")

```


$Pr(AB) = Pr(A) \cdot Pr(B) = 50\% \cdot 50\% = 25\%$

$Pr(A|B) = Pr(A,B) / Pr(B) = 25\% / 50\% = 50\%$


```{r child_verteilungen, eval = FALSE, child = "children/Verteilungen.Rmd"}

```


## Visualierung von (un)abhängigen Ereignissen

```{r}
source("R-Code/abhaengig.R")
```

Ändert sich die Wahrscheinlichkeit eines Ereignisses, wenn man es auf ein anderes bedingt, so sind beide Ereignisse abhängig, ansonsten unabhängig.



:::::: {.columns}
::: {.column width="50%"}
Abhängig
$P(A|B) \ne Pr(A) \ne Pr(A|\neg B)$
```{r out.width="100%"}
plottitanic1
```

\footnotesize
Überleben auf der Titanic ist abhängig von der Passagierklasse.
\normalsize

::: 
::: {.column width="50%"}
Unabhängig
$P(A|B) = Pr(A) = Pr(A|\neg B)$
```{r out.width="100%"}
plottitanic3 

```
\footnotesize
Überleben auf der Titanic ist *un*abhängig vom Ereignis *Alter ist eine Primzahl*.
\normalsize
:::
::::::




## Beispiel zur Visualisierung zweier abhängiger Ereignisse

Sind die Ereignisse *Tod durch Covid*  bzw. *Impfquote* ($A$) und *Land*^[hier mit den zwei Ausprägungen *DEU* und *USA*] ($B$) voneinander abhängig?

```{r covid1}
source("R-Code/covid01.R")

```

Ja, da in beiden Diagrammen gilt: $P(A|B) \ne Pr(A) \ne Pr(A|\neg B)$.

:::::: {.columns}
::: {.column width="50%"}

```{r plotcovid1}
plot_covid1
```

::: 
::: {.column width="50%"}
```{r plotcovid2}
plot_covid2
```
:::
::::::



\vspace{0.5cm}
Daten von [Our World in Data](https://ourworldindata.org/covid-deaths)

@owidcoronavirus



# Hinweise 


## Lehrbuch und Homepage des Lehrbuchs

Dieses Skript bezieht sich auf folgende [Lehrbücher](#literatur): 

- Kapitel 1 aus @gelman_regression_2021, *Regression and other Stories* (mit "ROS" abgekürzt)

- Kapitel 1 aus @mcelreath_statistical_2020 

- Rechenregeln sind z.B. in @cramer_vorkurs_2015 (Kap. 3) oder ähnlichen Lehrbüchern nachzulesen.


Dieses Skript wurde erstellt am `r Sys.time()`.



## Literatur {#literatur}

\tiny



<div id="refs"></div>


\normalsize
